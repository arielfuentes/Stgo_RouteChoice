@article{Dong2008,
   abstract = {A Voronoi diagram is an interdisciplinary concept that has been applied to many fields. In geographic information systems (GIS), existing capabilities for generating Voronoi diagrams normally focus on ordinary (not weighted) point (not linear or area) features. For better integration of Voronoi diagram models and GIS, a raster-based approach is developed, and implemented seamlessly as an ArcGIS extension using ArcObjects. In this paper, the methodology and implementation of the extension are described, and examples are provided for ordinary or weighted point, line, and polygon features. Advantages and limitations of the extensions are also discussed. The extension has the following features: (1) it works for point, line, and polygon vector features; (2) it can generate both ordinary and multiplicatively weighted Voronoi diagrams in vector format; (3) it can assign non-spatial attributes of input features to Voronoi cells through spatial joining; and (4) it can produce an ordinary or a weighted Euclidean distance raster dataset for spatial modeling applications. The results can be conveniently combined with other GIS datasets to support both vector-based spatial analysis and raster-based spatial modeling. © 2007 Elsevier Ltd. All rights reserved.},
   author = {Pinliang Dong},
   doi = {10.1016/j.cageo.2007.04.005},
   issn = {00983004},
   issue = {4},
   journal = {Computers and Geosciences},
   keywords = {Spatial analysis,Spatial joining,Spatial modeling,Thiessen polygon,Weighted Euclidean distance},
   month = {4},
   pages = {411-421},
   title = {Generating and updating multiplicatively weighted Voronoi diagrams for point, line and polygon features in GIS},
   volume = {34},
   year = {2008},
}
@article{Nielsen2000,
   abstract = {The paper presents a framework for public traffic assignment that builds on the probit-based model of Sheffi and Powell. Hereby, the problems with overlapping routes that occur in many public transport models can be avoided. The probit-based model with modifications similar to the principles in Nielsen is used as a starting point. This makes it possible to describe passengers' different preferences towards different sub-modes and against transfers. This also considers dependencies of choices through chains of sub-modes. The simulation of perceived travel times is extended to describe differences in the distribution of travel- and waiting times for different sub-modes. Parallel lines are frequency aggregated in order to handle waiting times appropriately. Initial tests on a full-scale case show that the methodology can describe route choices in public transport very well. This is both due to the model's ability to describe overlapping routes and due to the many different coefficients, error components and distributions that make it possible to calibrate the model. In practice, the many parameters might also be the main weakness, since this complicates the calibration. At the end of the paper, proposals to coefficients are presented based on a Danish SP-analysis. This demonstrated the applicability of the method.},
   author = {Otto Anker Nielsen},
   doi = {10.1016/S0191-2615(99)00029-6},
   issn = {01912615},
   issue = {5},
   journal = {Transportation Research Part B: Methodological},
   month = {6},
   pages = {377-402},
   publisher = {Elsevier Science Ltd},
   title = {A stochastic transit assignment model considering differences in passengers utility functions},
   volume = {34},
   year = {2000},
}
@inbook{Gentile2016,
   abstract = {This chapter addresses the modelling of various demand and supply phenomena emerging on public transport networks: passenger information, congestion at stops and on board, and service regularity.},
   author = {Guido Gentile and Klaus Noekel and Jan Dirk Schmöcker and Valentina Trozzi and Ektoras Chandakas},
   doi = {10.1007/978-3-319-25082-3_7},
   issn = {21948127},
   issue = {9783319250809},
   journal = {Springer Tracts on Transportation and Traffic},
   pages = {387-481},
   publisher = {Springer International Publishing},
   title = {The theory of transit assignment: Demand and supply phenomena},
   year = {2016},
}
@inbook{Gentile2016,
   abstract = {In this chapter, the different basic assumptions for the development of assignment models to transit networks (frequency-based, schedule-based) are presented together with the possible approaches to the simulation of the dynamic system (steady state, macroscopic flows, agent-based).},
   author = {Guido Gentile and Michael Florian and Younes Hamdouch and Oded Cats and Agostino Nuzzolo},
   doi = {10.1007/978-3-319-25082-3_6},
   issn = {21948127},
   issue = {9783319250809},
   journal = {Springer Tracts on Transportation and Traffic},
   pages = {287-386},
   publisher = {Springer International Publishing},
   title = {The theory of transit assignment: Basic modelling frameworks},
   year = {2016},
}
@article{Tribby2017,
   abstract = {Walking is a form of active transportation with numerous benefits, including better health outcomes, lower environmental impacts and stronger communities. Understanding built environmental associations with walking behavior is a key step towards identifying design features that support walking. Human mobility data available through GPS receivers and cell phones, combined with high resolution walkability data, provide a rich source of georeferenced data for analyzing environmental associations with walking behavior. However, traditional techniques such as route choice models have difficulty with highly dimensioned data. This paper develops a novel combination of a data-driven technique with route choice modeling for leveraging walkability audits. Using data from a study in Salt Lake City, UT, USA, we apply the data-driven technique of random forests to select variables for use in walking route choice models. We estimate data-driven route choice models and theory-driven models based on predefined walkability dimensions. Results indicate that the random forest technique selects variables that dramatically improve goodness of fit of walking route choice models relative to models based on predefined walkability dimensions. We compare the theory-driven and data-driven walking route choice models based on interpretability and policy relevance.},
   author = {Calvin P. Tribby and Harvey J. Miller and Barbara B. Brown and Carol M. Werner and Ken R. Smith},
   doi = {10.1177/0265813516659286},
   issn = {23998091},
   issue = {6},
   journal = {Environment and Planning B: Urban Analytics and City Science},
   keywords = {Walkability,built environment,random forests,route choice},
   month = {11},
   pages = {1145-1167},
   publisher = {SAGE Publications Ltd},
   title = {Analyzing walking route choice through built environments using random forests and discrete choice techniques},
   volume = {44},
   year = {2017},
}
@article{Raveau2011,
   abstract = {This article presents a route choice model for public transit networks that incorporates variables related to network topology, complementing those found in traditional models based on service levels (travel time, cost, transfers, etc.) and users' socioeconomic and demographic characteristics (income level, trip purpose, etc.). The topological variables represent concepts such as the directness of the chosen route and user knowledge of the network. For both of these factors, the necessary data is endogenous to the modelling process and can be quantified without the need for information-gathering beyond what is normally required for building route choice models. Other novel variables in the proposed formulation capture notions of user comfort such as vehicle occupancy rates and certain physical characteristics of network stations. We conclude that these new variables significantly improve the explanatory and predictive ability of existing route choice specifications. © 2010 Elsevier Ltd.},
   author = {Sebastián Raveau and Juan Carlos Muñoz and Louis de Grange},
   doi = {10.1016/j.tra.2010.12.004},
   issn = {09658564},
   issue = {2},
   journal = {Transportation Research Part A: Policy and Practice},
   keywords = {Angular cost,Model specification,Network topology,Perceptions,Route choice},
   month = {12},
   pages = {138-147},
   publisher = {Elsevier Ltd},
   title = {A topological route choice model for metro},
   volume = {45},
   year = {2011},
}
@article{Cho2021,
   abstract = {Modelling route choice behaviours are essential in traffic operation and transportation planning. Many studies have focused on route choice behaviour using the stochastic model, and they have tried to construct the heterogeneous route choice model with various types of data. This study aims to develop the route choice model incorporating travellers' heterogeneity according to the stochastic route choice set. The model is evaluated from the empirical travel data based on a radio frequency identification device (RFID) called dedicated short-range communication (DSRC). The reliability level is defined to explore the travellers' heterogeneity in the choice set generation model. The heterogeneous K-reliable shortest path- (HKαRSP-) based route choice model is established to incorporate travellers' heterogeneity in route choice behaviour. The model parameters are estimated for the mixed path-size correction logit (MPSCL) model, considering the overlapping paths and the heterogeneous behaviour in the route choice model. The different behaviours concerning the chosen routes are analysed to interpret the route choice behaviour from revealed preference data by comparing the different coefficients' magnitude. There are model validation processes to confirm the prediction accuracy according to travel distance. This study discusses the policy implication to introduce the traveller specified route travel guidance system.},
   author = {Shin Hyung Cho and Seung Young Kho},
   doi = {10.1155/2021/5530814},
   issn = {20423195},
   journal = {Journal of Advanced Transportation},
   publisher = {Hindawi Limited},
   title = {Exploring Route Choice Behaviours Accommodating Stochastic Choice Set Generations},
   volume = {2021},
   year = {2021},
}
@inproceedings{Brands2014,
   abstract = {Public transport (PT) is important, because the current traffic system faces well known problems like congestion, environmental impact and use of public space. To be able to assess the effects of policy measures properly, it is necessary to model the behavior of the (PT) traveler in a realistic way. An aspect that lacks realism in a lot of current models is the rigid separation between modes: within the model a traveler cannot choose to switch between modes, so multimodal trips that combine a public transport trip with the car or with the bicycle are not (or at least not explicitly) taken into account, while the use of the bicycle as an access mode is very popular in the Netherlands, and getting more popular in other countries. Easy bike rental systems enable use as an egress mode as well. The use of the car as an access mode is very popular in the US. Furthermore, multiple routing is important, because different users have different preferences (i.e. a fast route or a route without a transfer). These two aspects are addressed in this paper, to achieve more realistic transit modeling. Multiple routing is included by further developing the method of optimal strategies, where the departure time of vehicles is taken into account in order to determine whether a choice option is the shortest route for some moment in time. This results in a static route choice algorithm that is capable to assess large scale networks. By defining a search radius for different access and egress modes and by defining a sensible set of transit lines, the calculation time of the algorithm is kept limited. Logit choice models are used for stop choice and line choice, to calculate the fractions of travelers that take each route alternative. The route choice model calculates cost matrices for several mode chains. These mode chains include single mode travel options (like the car or PT combined with walking), but also multimodal travel options (that always include a PT leg). These cost matrices are incorporated in the mode choice process with a nested logit model to determine mode choice. This results in an OD matrix for all modes and mode chains. Finally, these OD matrices are assigned to the network, again using the route choice model. Applying this modeling framework to a real world case study in the Amsterdam metropolitan area shows that the computation times are reasonable, the results are plausible and conceptually sound. This enables modelers for example to assess infrastructural network developments in large scale networks, taking into account realistic behavior of travelers, namely the combination of multiple modes to reach their destination.},
   author = {Ties Brands and Erik De Romph and Tim Veitch and Jamie Cook},
   doi = {10.1016/j.trpro.2014.07.003},
   issn = {23521465},
   issue = {1},
   journal = {Transportation Research Procedia},
   keywords = {PT assignment,multimodal passenger network modelling,multiple routing},
   pages = {12-23},
   publisher = {Elsevier},
   title = {Modelling Public Transport Route Choice, with Multiple Access and Egress Modes},
   volume = {1},
   year = {2014},
}
@article{Rocio2021,
   abstract = {The need for effective freight and human transportation systems has consistently increased during the last decades, mainly due to factors such as globalization, e-commerce activities, and mobility requirements. Traditionally, transportation systems have been designed with the main goal of reducing their monetary cost while offering a specified quality of service. During the last decade, however, sustainability concepts are also being considered as a critical component of transportation systems, i.e., the environmental and social impact of transportation activities have to be taken into account when managers and policy makers design and operate modern transportation systems, whether these refer to long-distance carriers or to metropolitan areas. This paper reviews the existing work on different scientific methodologies that are being used to promote Sustainable Transportation Systems (STS), including simulation, optimization, machine learning, and fuzzy sets. This paper discusses how each of these methodologies have been employed to design and efficiently operate STS. In addition, the paper also provides a classification of common challenges, best practices, future trends, and open research lines that might be useful for both researchers and practitioners.},
   author = {Rocio de la Torre and Canan G. Corlu and Javier Faulin and Bhakti S. Onggo and Angel A. Juan},
   doi = {10.3390/su13031551},
   issn = {20711050},
   issue = {3},
   journal = {Sustainability (Switzerland)},
   keywords = {Machine learning,Optimization,Simulation,Sustainability,Transportation systems},
   month = {2},
   pages = {1-21},
   publisher = {MDPI AG},
   title = {Simulation, optimization, and machine learning in sustainable transportation systems: Models and applications},
   volume = {13},
   year = {2021},
}
@article{Su2021,
   author = {Yue Su and Wenbo Fan and Jakob Puchinger and Minyu Shen},
   keywords = {United States ï¿¿hal-03131516ï¿¿,Washington DC},
   title = {A Deep-Learning Approach for Network Traffic Assignment with Incomplete Data},
   url = {https://hal.archives-ouvertes.fr/hal-03131516},
   year = {2021},
}
@article{Wang2021,
   abstract = {Regional population forecast and analysis is of essence to urban and regional planning, and a well-designed plan can effectively construct a sound national infrastructure and stabilize positive population growth. Traditionally, either urban or regional planning relies on the opinions of demographers in terms of how the population of a city or a region will grow. Multi-regional population forecast is currently possible, carried out mainly on the basis of the Interregional Cohort-Component model. While this model has its unique advantages, several demographic rates are determined based on the decisions made by primary planners. Hence, the only drawback for cohort-component type population forecasting is allowing the analyst to specify the demographic rates of the future, and it goes without saying that this tends to introduce a biased result in forecasting accuracy. To effectively avoid this problem, this work proposes a machine learning-based method to forecast multi-regional population growth objectively. Thus, this work, drawing upon the newly developed machine learning technology, attempts to analyze and forecast the population growth of major cities in Taiwan. By effectively using the advantage of the XGBoost algorithm, the evaluation of feature importance and the forecast of multi-regional population growth between the present and the near future can be observed objectively, and it can further provide an objective reference to the urban planning of regional population.},
   author = {Chian Yue Wang and Shin Jye Lee},
   doi = {10.3390/e23060656},
   issn = {10994300},
   issue = {6},
   journal = {Entropy},
   keywords = {Boosting regression,Population growth prediction},
   month = {6},
   publisher = {MDPI AG},
   title = {Regional population forecast and analysis based on machine learning strategy},
   volume = {23},
   year = {2021},
}
@inbook{Har-Peled2011,
   author = {Sariel Har-Peled},
   city = {Providence, Rhode Island},
   editor = {Ralph L. Cohen and Michael L. Singer and Eric M. Friedlander and Benjamin Sudakov and MIchael I. Weinstein},
   isbn = {978-0-8218-4911-8},
   journal = {Geometric Approximation Algorithms},
   pages = {13-28},
   publisher = {American Mathematical Society},
   title = {Quadtrees – Hierarchical Grids},
   volume = {173},
   year = {2011},
}
@book{Gujarati2010,
   author = {Damodar N. Gujarati and Dawn C. Porter},
   city = {México, D. F.},
   isbn = {978-607-15-0294-0},
   title = {Econometría},
   year = {2010},
}
@inbook{Boots1999,
   author = {Byron Boots},
   city = {New York},
   edition = {2},
   editor = {Paul A. Longley and Michael A. Goodchild and David A. Maguire and David W. Rhind},
   isbn = {0471–33132–5},
   journal = {GEOGRAPHICAL INFORMATION SYSTEMS},
   pages = {503-526},
   publisher = {JOHN WILEY & SONS, INC.},
   title = {Spatial tessellations},
   volume = {1},
   year = {1999},
}
@book{Ortúzar2008,
   author = {Juan de Dios Ortúzar and Luis G. Willumsen},
   city = {Santander, España},
   edition = {3},
   isbn = {978-84-8102-512-5},
   publisher = {PUbliCan - Ediciones de la Universidad de Cantabria},
   title = {Modelos de Transporte},
   year = {2008},
}
@inproceedings{Eurostat2018,
   abstract = {Management (UN-GGIM) "acknowledged the critical importance of integrating geospatial information with statistics and socioeconomic data and the development of a geospatial statistical framework". There is a growing importance of taking spatial phenomena into account and, as a consequence, the need for geolocated data are also increasing. To this end, the French national institute of statistics and economic studies (INSEE) has undertaken a reworking of its geographical information system. This handbook, coordinated by Insee thanks to a Eurostat grant, shows what kind of analysis can be achieved and the pitfalls one has to avoid once geolocated data is available. The purpose of this spatial analysis handbook is to answer the questions faced by research teams at statistical institutes. What use should be made of the new geolocated data sources? In what cases should their spatial dimension be taken into account? How should spatial statistical and spatial econometric methods be applied? In contrast to existing manuals, the teaching principle of this handbook has been designed expressly according to the issues specific to statistical institutes, such as spatial sampling, spatial econometrics, confidentiality or spatial smoothing. The handbook is divided into four parts. The first three match the stages one would follow to carry out a study: describing the location of the observations, measuring spatial interactions and applying the appropriate model. Each of the fourteen chapters deals with a specific subject by explaining the theoretical foundations, giving educational examples based on data coming from public statistical institutes, and displaying how to use the R statistical software to carry out the computations.},
   author = {Insee Eurostat},
   isbn = {978-2-11-139685-2},
   issn = {1259-4768},
   title = {Handbook of Spatial Analysis: Theory and practical application with R},
   url = {www.insee.fr},
   year = {2018},
}
@inproceedings{Anselin2021,
   abstract = {Since its introduction more than 15 years ago, the GeoDa software for the exploration of spatial data has transitioned from a closed source Windows-only solution to an open source and cross-platform product that takes on the look and feel of the native operating system. This article reports on the evolution in the functionality and architecture of the software and pays particular attention to its new implementation as a library, libgeoda. This library, through a clearly structured API, can be integrated into other software environments, such as R (rgeoda) and Python (pygeoda). This integration is illustrated with two small empirical examples, investigating local clusters in a historical London cholera data set and among socioeconomic determinants of health in Chicago. A timing experiment demonstrates the competitive performance of GeoDa desktop, libgeoda (C++), rgeoda and pygeoda compared to established solutions in R spdep and Python PySAL, evaluating conditional permutation inference for the Local Moran statistic.},
   author = {Luc Anselin and Xun Li and Julia Koschinsky},
   doi = {10.1111/gean.12311},
   issn = {15384632},
   journal = {Geographical Analysis},
   publisher = {John Wiley and Sons Inc},
   title = {GeoDa, From the Desktop to an Ecosystem for Exploring Spatial Data},
   year = {2021},
}
@article{Hoef2018,
   abstract = {We clarify relationships between conditional (CAR) and simultaneous (SAR) autoregressive models. We review the literature on this topic and find that it is mostly incomplete. Our main result is that a SAR model can be written as a unique CAR model, and while a CAR model can be written as a SAR model, it is not unique. In fact, we show how any multivariate Gaussian distribution on a finite set of points with a positive-definite covariance matrix can be written as either a CAR or a SAR model. We illustrate how to obtain any number of SAR covariance matrices from a single CAR covariance matrix by using Givens rotation matrices on a simulated example. We also discuss sparseness in the original CAR construction, and for the resulting SAR weights matrix. For a real example, we use crime data in 49 neighborhoods from Columbus, Ohio, and show that a geostatistical model optimizes the likelihood much better than typical first-order CAR models. We then use the implied weights from the geostatistical model to estimate CAR model parameters that provides the best overall optimization.},
   author = {Jay M. Ver Hoef and Ephraim M. Hanks and Mevin B. Hooten},
   doi = {10.1016/j.spasta.2018.04.006},
   issn = {22116753},
   journal = {Spatial Statistics},
   keywords = {Areal models,Covariance matrix,Lattice models,Spatial statistics},
   month = {6},
   pages = {68-85},
   publisher = {Elsevier B.V.},
   title = {On the relationship between conditional (CAR) and simultaneous (SAR) autoregressive models},
   volume = {25},
   year = {2018},
}
@report{Kinene2016,
   author = {Alan Kinene},
   title = {Modelling the Passenger Demand for Buses in Örebro City},
   year = {2016},
}
@inproceedings{Hagen-Zanker2015,
   abstract = {Transport modelling and in particular transport assignment is a wellknown bottleneck in computation cost and time for urban system models. The use of Transport Analysis Zones (TAZ) implies a trade-off between computation time and accuracy: practical computational constraints can lead to concessions to zone size with severe repercussions for the quality of the transport representation in urban models. This paper investigates how a recently developed geographical topology called adaptive zoning can be used to obtain more favorable trade-offs between computational cost and accuracy than traditional TAZ. Adaptive zoning was developed specifically for representing spatial interactions; it makes use of a nested zone hierarchy to adapt the model resolution as a function of both the origin and destination location. In this paper the adaptive zoning method is tied to an approach to trip assignment that uses high spatial accuracy (small zones) at one end of the route and low spatial accuracy (large zones) at the other end of the route. Opportunistic use of either the first or second half of such routes with asymmetric accuracy profiles leads to a method of transport assignment that is more accurate than traditional TAZ based assignment at reduced computational cost. The method is tested and demonstrated on the well-known Chicago Regional test problem. Compared with an assignment using traditional zoning, an adaptive-zoning-based assignment that uses the same computation time reduces the bias in travel time by a factor 16 and link level traffic volume RMSE by a factor 6.4.},
   author = {Alex Hagen-Zanker and Ying Jin},
   doi = {10.1007/978-3-319-21470-2_49},
   isbn = {9783319214696},
   issn = {16113349},
   journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
   keywords = {Assignment,TAZ,Transport,Zone},
   pages = {673-687},
   publisher = {Springer Verlag},
   title = {Adaptive zoning for efficient transport modelling in urban models},
   volume = {9157},
   year = {2015},
}
@article{Herijanto2020,
   abstract = {It is challenging to have a trip attraction model that fits Surabaya's surveyed data due to unclear city centre structure. These include the centrum of concentric, corridors of sectoral, or several centres of multiple-nuclei structures. Also, the layout of residential areas has unconventional patterns. This is because the planned housing development area is wrongly inserted on kampong and sometimes lies in city centre. This paper examines the influence of single-centre districts, corridors, or multiple suburb centre structures on trip attraction. The analysis was conducted using origin-destination data from the household interview survey by The Transportation Board of Surabaya and several houses digitized from a relevant year's satellite image. The distance and position information was taken from the Google Earth application. The zonal analysis trip attraction model based on the sub-district zoning system was analysed using fixed trip production data and simulated independent variables. The independent variables included the zonal activity areas such as shops, offices, and industries in sub-district, while the dependent variables consisted of the straight distances from the sub-district to city centres. Several models were tested based on the dependent and independent variables. The results show that the combined zonal activity area and spatial variables have a stronger influence on zonal trip attraction than the conventional model using zonal labor and student variable, mainly based on the urban geographical pattern.},
   author = {W. Herijanto and I. B. Mochtar and A. Wicaksono},
   doi = {10.18517/ijaseit.10.4.12820},
   issn = {24606952},
   issue = {4},
   journal = {International Journal on Advanced Science, Engineering and Information Technology},
   keywords = {Concentric,Multiple-nuclei,Sector,Surabaya,Transportation,Trip attraction},
   pages = {1591-1596},
   publisher = {Insight Society},
   title = {Improvement of trip attraction model in surabaya by considering geographical weighting of city centre activity function},
   volume = {10},
   year = {2020},
}
@article{Cheng2019,
   abstract = {When multiple routes connect the same origin and destination (OD), passenger route choices are related to the operation and management of urban rail transit, including the design of the train plan, fare clearing, and passenger distribution. The passengers’ travel data from an automatic fare collection (AFC) system provides useful data for the analysis of passenger route choices. We propose an estimation method of passenger route choices based on AFC data, which includes passenger’s travel time and OD. In this paper, the AFC data used for analysis were mined to eliminate unreasonable individual travel data. In this study, the components of passenger travel times and their influencing factors are analyzed and the results indicate that the travel times are related to the route choices of passengers. Cluster analysis indicated that passenger travel times follow the logarithmic normal distribution. Based on this and a multi-route distribution sample, an estimation model for passenger route choice proportions is proposed. Furthermore, experimental results show that the data mining method has high accuracy and the result also supported the hypothesis about the travel time distribution. The model was applied to the Chengdu metro, which is one of the largest metro systems in the world, and the obtained results indicate that the model works well. In addition to the initial application, the estimation method provides a new method to calculate the route choice proportion for urban rail transit with maximum dependability and timeliness.},
   author = {Gang Cheng and Shuzhi Zhao and Shengbo Xu},
   doi = {10.1177/0142331218823855},
   issn = {01423312},
   issue = {11},
   journal = {Transactions of the Institute of Measurement and Control},
   keywords = {Urban rail transit system,data mining,distribution of travel time,route choice model,travel time influenced factors},
   month = {7},
   pages = {3092-3102},
   publisher = {SAGE Publications Ltd},
   title = {Estimation of passenger route choices for urban rail transit system based on automatic fare collection mined data},
   volume = {41},
   year = {2019},
}
@inproceedings{Villalobos2021,
   abstract = {RESUMEN En la modelación de elecciones discretas, el conjunto de consideración contiene las alternativas para realizar una elección. Este conjunto es difícil de conocer y, representarlo erróneamente, redundará en modelos incapaces de representar la realidad, entregando estimadores inconsistentes y errores de predicción. Este trabajo realiza tres contribuciones abordando este desafío. La primera utiliza simulaciones de Monte Carlo para explorar la robustez de métodos prácticos utilizados para construir este conjunto, mostrando que métodos tradicionales generan sesgos en la estimación y que utilizar elecciones históricas presenta resultados prometedores. La segunda analiza tres métodos para recolectar datos sobre este conjunto: datos pasivos, encuesta online y encuesta sobre mapa. Los datos pasivos tienen la ventaja de mostrar preferencias reveladas, pero requieren mucho procesamiento. Las encuestas mostraron ser factibles a nivel exploratorio, pero son susceptibles al sesgo hipotético y recolectarlos es costoso. La tercera utiliza un experimento de preferencias declaradas intentando replicar el proceso de generación del conjunto para estudiar sus características y probar la robustez de ciertos métodos para construirlo. Este ejercicio permitió describir el tamaño del conjunto, identificar heurísticas que la gente dice utilizar para generarlo, además de modelar el proceso de consideración. El artículo concluye resumiendo las contribuciones, limitaciones y alcances prácticos del trabajo. ABSTRACT In discrete choices, the consideration set offers the alternatives to make a choice. This set is difficult to know, and any mistake will imply that models will not represent reality, delivering inconsistent estimator and prediction error. This paper makes three contribution to face this challenge. The first one uses Monte Carlo simulations to explore the robustness of practical methods to build this set, showing that traditional methods cause bias in the estimations, whereas using historical events provides promising results. The second one analyzes three methods to gather data on this set: passive data, online and map survey. Passive data have the advantage of showing revealed preferences but require a lot of processing. Data gathered by surveys showed to be feasible, but susceptible to hypothetical bias and gathering them was expensive. The third one uses a declared preferences experiment trying to replicate the process of generating this set, to study its characteristics and demonstrate robustness of certain methods used to build it. This exercise allowed us to describe the size of the set, identify heuristics that people say that they use, and to model the process of consideration. The article finishes with the contributions, limitations, and practical implications of this paper.},
   author = {G Nicolás Villalobos and C Angelo Guevara},
   keywords = {Monte Carlo,RP,SP,consideration set,discrete choice},
   pages = {1-26},
   title = {CARACTERIZACIÓN DEL CONJUNTO DE CONSIDERACIÓN EN ELECCIÓN DE RUTA},
   volume = {22},
   year = {2021},
}
@inproceedings{Bakhtyar2015,
   abstract = {We present a method, which makes use of historical vehicle data and current vehicle observations in order to estimate 1) the route a vehicle has used and 2) the freight the vehicle carried along the estimated route. The method includes a learning phase and an estimation phase. In the learning phase, historical data about the movement of a vehicle and of the consignments allocated to the vehicle are used in order to build estimation models: one for route choice and one for freight allocation. In the estimation phase, the generated estimation models are used together with a sequence of observed positions for the vehicle as input in order to generate route and freight estimates. We have partly evaluated our method in an experimental study involving a medium-size Swedish transport operator. The results of the study indicate that supervised learning, in particular the algorithm Naive Bayes Multinomial Updatable, shows good route estimation performance even when significant amount of information about where the vehicle has traveled is missing. For the freight estimation, we used a method based on averaging the consignments on the historical known trips for the estimated route. We argue that the proposed method might contribute to building improved knowledge, e.g., in national road administrations, on the movement of trucks and freight.},
   author = {Shoaib Bakhtyar and Johan Holmgren},
   doi = {10.1016/j.procs.2015.05.004},
   issn = {18770509},
   issue = {1},
   journal = {Procedia Computer Science},
   keywords = {Freight estimation,Naive Bayes multinomial;,Route estimation,Supervised learning},
   pages = {396-403},
   publisher = {Elsevier B.V.},
   title = {A data mining based method for route and freight estimation},
   volume = {52},
   year = {2015},
}
@article{Lee2014,
   abstract = {Various geographic units have been used in macro-level modeling. Amongst these units, traffic analysis zones (TAZs) have been broadly employed in many macroscopic safety studies. Nevertheless, no studies questioned the validity of TAZs for crash analysis at the macro-level crash modeling. In this study, we point out several possible problems of TAZs as spatial units for macroscopic safety studies. Current TAZs with homogenous crash rates were combined into new single zones. Then we created ten new zonal systems by different zone aggregation levels. The optimal zonal scale for traffic safety analysis zones (TSAZ) was determined using the Brown-Forsythe test. It was found that the zone system with about 1:2 aggregation was the optimal zone system for macroscopic safety modeling. Thus we develop what we call traffic safety analysis zones (TSAZs) that has the potential of reducing several possible problems of TAZs. Also it was shown that TSAZ based models had better fit compared to TAZ based models. © 2014 Elsevier Ltd.},
   author = {Jaeyoung Lee and Mohamed Abdel-Aty and Ximiao Jiang},
   doi = {10.1016/j.jtrangeo.2014.04.018},
   issn = {09666923},
   journal = {Journal of Transport Geography},
   keywords = {Bayesian Poisson Log-normal model,MAUP,Macro-level analysis,Regionalization,Traffic safety analysis zones,Transportation safety planning},
   pages = {13-21},
   publisher = {Elsevier Ltd},
   title = {Development of zone system for macro-level traffic safety analysis},
   volume = {38},
   year = {2014},
}
@article{Ghadiri2019,
   abstract = {One of the first and most critical steps involved in transportation studies is to determine the traffic zoning scheme. A traffic analysis zone (TAZ) is the main unit of the transportation analysis. In most transportation planning studies, the focus is only on the modeling process, while ignoring aspects such as TAZ definition, configuration, and design. Although the definition of TAZs is one of the key stages in transportation planning studies, a proper approach for the definition is still one of the unsolved issues. In this research, a TAZ with regular geometric shapes, called regular traffic analysis zones (RTAZs), is presented as a new approach to traffic zoning. On the other hand, the accuracy of calculating trip production, as the first step of well-known 4-step transportation demand modeling system, is of high necessity, because this step determines the total number of trips. In the current study, the effects of RTAZs on the results of trip production models (TPMs) for the city of Khoy in Iran were investigated. The results indicated that TPMs based on regular zoning system acted almost similar to traditional zoning system in estimating produced trips and, in some cases, even presented relatively better estimations. Regarding the difficulties encountered in the topic of the traditional traffic zoning system, the present work showed that RTAZs facilitated the modeling process and led to time and cost savings.},
   author = {Mehdi Ghadiri and Amir Abbas Rassafi and Babak Mirbaha},
   doi = {10.1016/j.jtrangeo.2019.05.018},
   issn = {09666923},
   journal = {Journal of Transport Geography},
   keywords = {MAUP,Regular geometric shapes,TAZ,Traffic analysis zone,Traffic zoning,Transportation planning,Trip production model},
   month = {6},
   pages = {150-159},
   publisher = {Elsevier Ltd},
   title = {The effects of traffic zoning with regular geometric shapes on the precision of trip production models},
   volume = {78},
   year = {2019},
}
@article{Binetti,
   author = {Mario G Binetti and Ernesto Ciani},
   title = {EFFECTS OF TRAFFIC ANALYSIS ZONES DESIGN ON TRANSPORTATION MODELS},
}
@inproceedings{Pljakić2018,
   abstract = {Spatial analysis of traffic accidents is of great importance for understanding the conditions when accidents occur in order to plan preventive activities at a specific locations. The analysis of spatial autocorrelation is of great importance in assessing the impact relationship of different spatial entities. The data for the analysis in this paper is the traffic accidents that occurred in the area of the city of Novi Sad in the three-year period (2015-2017). During the analyzed period, in area the Novi Sad occurred 4990 traffic accidents in 248 traffic analysis zones. Using the spatial autocorrelation method was observed a spatial relationship between the traffic analysis zones in which have occurred accidents. The results are present the high value of local Moran I statistics and GI * statistics where the spatial grouping of the high frequency of the total number of accidents and accidents with pedestrians. These results can be of exceptional benefit to transport planners as well as all decision makers in traffic safety in the Novi Sad. It will be more actively applied with developments in data collection, software technology and implementation of new models and methods being researched in futures.},
   author = {Miloš Pljakić and Đorđe Basarić and Srbislav Gugleta},
   keywords = {21000,21000 Novi Sad,Accident analysis,Novi Sad,Sad,Serbia,Spatial autocorrelation,Stevana Branovačkog 3,Trg Dositeja Obradovića 6,djordjebasaric@upravanovisadrs 3 City Administration for Building Land and Investments,pljakic@unsacrs 2 City Administration for Transport and Roads,srbislav Keywords: Traffic analysis zones,Žarka Zrenjanina 2},
   title = {SPATIAL CLUSTERING OF TRAFFIC ANALYSIS ZONE: A CASE STUDY FROMNOVI SAD, SERBIA},
   url = {https://www.researchgate.net/publication/328392920},
   year = {2018},
}
@article{Altan2018,
   abstract = {In this work we have studied the selection criteria for traffic analysis zones and the effects of their size and number on the model’s forecasting capabilities. To do so we have focused on the corridor of Istanbul’s Kadiköy-Kartal Metro Line and evaluated the consistency of demand forecasts and travel assignments versus actual measurements under different sizes of the Traffic Analysis Zones (TAZ). Significant improvements in model accuracy were observed by decreasing the zone size. Specifically, studying the public transport network assignments for the metro line when increasing the number of traffic analysis zones from 540 to 1,788 the root mean square error (RMSE) of forecasted vs. actual station-based counts was reduced by 23%. Subsequently, the study used population density and employment density as independent variables for the determination of the optimal radius for the 1,788 zone area, and applied an exponential regression model. Appropriate model parameters were derived for the above case study. The regression model resulted in R2 values over 0.62.},
   author = {Mehmet Fatih Altan and Yunus Emre Ayözen},
   doi = {10.3311/PPci.11885},
   issn = {15873773},
   issue = {4},
   journal = {Periodica Polytechnica Civil Engineering},
   keywords = {Traffic analysis zones,Transportation model,Travel assignments,Travel demand forecast},
   pages = {971-979},
   publisher = {Budapest University of Technology and Economics},
   title = {The effect of the size of traffic analysis zones on the quality of transport demand forecasts and travel assignments},
   volume = {62},
   year = {2018},
}
@article{You1998,
   abstract = {The purpose of this paper is to implement an efficient method for GIS-based traffic analysis zone (TAZ) design in order to evaluate and validate such a method. The method was developed by the authors. Moran's I spatial autocorrelation coefficient and sample variance are used for evaluating the generated TAZs using the Champaign-Urbana, IL region as a case study. Sensitivity analysis is also conducted to explore the fluctuations in TAZ generation outcomes. The evaluation, the validation as well as the TAZ design have been implemented with ARC/INFO GIS software on a UNIX workstation platform.},
   author = {Jinsoo You and Zorica Nedović-Budić and Tschangho John Kim},
   doi = {10.1080/03081069708717602},
   issn = {03081060},
   issue = {1-2},
   journal = {Transportation Planning and Technology},
   keywords = {Evaluation,Geographic Information System (GIS),Geographic Information Systems for Transportation (GIS-T),Spatial Autocorrelation,Traffic Analysis Zone (TAZ),Transportation Demand Modeling,Validation},
   pages = {69-91},
   publisher = {Taylor and Francis Ltd.},
   title = {A GIS-based traffic analysis zone design: Implementation and evaluation},
   volume = {21},
   year = {1998},
}
@article{You1998,
   abstract = {The main purpose of this paper is to develop an efficient method to design traffic analysis zones (TAZs), which is necessary for implementing a planning process with Geographic Information System (GIS) for Transportation (GIS-T), using statistical spatial data analyses and GIS technology. The major roles of GIS in this method are: (1) to produce basic spatial units (BSUs) with topological data structure; (2) to integrate various procedures during the TAZ generation including computer program routines; and (3) to visualize the output of each TAZ generation. One of the most significant reasons for obtaining well-defined TAZs is the fact that they are defined at the outset of transportation demand modeling, used from trip generation to trip assignment, and will ultimately affect transportation policy decisions. Toward obtaining well-defined TAZs, this paper concentrates on two important constraints: homogeneity and contiguity. Iterative partitioning technique is adopted to promote the optimum homogeneity of generated TAZs, while a contiguity checking algorithm is developed to ensure contiguous TAZs are generated by the iterative partitioning technique.},
   author = {Jinsoo You and Zorica Nedović-Budić and Tschangho John Kim},
   doi = {10.1080/03081069708717601},
   issn = {03081060},
   issue = {1-2},
   journal = {Transportation Planning and Technology},
   keywords = {Contiguity Recognition,Geographic Information System (GIS),Geographic Information Systems for Transportation (GIS-T),Iterative partitioning,Traffic Analysis Zone (TAZ),Transportation Demand Modeling},
   pages = {45-68},
   publisher = {Taylor and Francis Ltd.},
   title = {A GIS-based traffic analysis zone design: Technique},
   volume = {21},
   year = {1998},
}
@article{Guo2014,
   abstract = {The zone system used for freight data collection and the geographic resolution of published data has a significant impact on analysis and planning. The majority of existing freight model zones are created in an ad hoc way. In this paper, a new model-based design method is introduced to develop freight zones for the continental USA. It focuses on two methodology issues: (1) the criteria that represent the desired properties of a zone system and (2) the constraints that govern the shape, size, and continuity of zones. The method is applied to the continental USA by optimizing an interzonal travel distance weighted by freight flows using county-level freight data. Several optimal national-level freight zone systems with different numbers of zones are developed. The results indicate that a 300-zone system provides a balance between the number of zones and optimization measures where the currently available public freight data are provided with approximately 100 zones.},
   author = {Feng Guo and Lisa Aultman-Hall},
   doi = {10.1080/03081060.2014.959355},
   issn = {10290354},
   issue = {8},
   journal = {Transportation Planning and Technology},
   keywords = {USA,freight data collection,freight model zones,freight transportation,modeling,optimization algorithm},
   month = {11},
   pages = {738-756},
   publisher = {Routledge},
   title = {A zone design methodology for national freight origin–destination data and transportation modeling},
   volume = {37},
   year = {2014},
}
@inproceedings{Weerasinghe2019,
   abstract = {"Part Number: CFP19B72-ART"--PDF copyright page.},
   author = {Oshadhi Weerasinghe and Saman Bandara},
   isbn = {9781728136325},
   publisher = {Moratuwa Engineering Research Conference},
   title = {A GIS Based Methodology to Demarcate Modified Traffic Analysis Zones in Urban Areas},
   year = {2019},
}
@inproceedings{Xue2010,
   abstract = {When transportation engineers try to monitor the trend of congestions to early warning the connectivity deterioration between every two important districts, problem they meet first is how to divide urban area into small zones which can fit the connectivity and accessibility analysis. In this paper, we solved this problem by calculating and analyzing the topological structure of road network. After comparing several indices, we found Local Depth value in Space Syntax theory is very suitable for helping the zone division. At last, we apply this method in Shanghai urban area and get an encouraging result. Moreover, most of accessibility oriented zones divided by local depth value also agrees well with people's cognition of regions. ©2010 IEEE.},
   author = {Yuan Xue and Zhengyu Duan},
   doi = {10.1109/CAR.2010.5456782},
   isbn = {9781424451937},
   journal = {CAR 2010 - 2010 2nd International Asia Conference on Informatics in Control, Automation and Robotics},
   keywords = {Space syntax,Traffic analysis zone division},
   pages = {516-519},
   title = {An accessibility oriented traffic analysis zone division method},
   volume = {1},
   year = {2010},
}
@article{Yao2021,
   abstract = {Due to regional development impacts, existing traffic analysis zones may be rezoned. Apportioning data to new traffic analysis zones is essential to ensure data analysis consistency and comparability. The traditional method uses area to apportion data. This study introduces six methods in apportioning trip data, including the traditional method (M1); the residential land use counted method (M2); the population counted at the dissemination area (DA) level method (M3); the integrated method using both residential land use and the population in DAs (M4); the population counted at the dissemination block (DB) level method (M5); and the integrated method using both residential land use and the population in DBs (M6). These methods are demonstrated in the case of Toronto, Canada using trip data from 2001 and 2016. Results from the six methods are compared and analyzed using mapping, Getis-Ord Gi* hot-spot analysis, and the Wilcoxon signed-rank test. Our findings show that the traditional method and the population counted in DAs method are significantly different (p < 0.05) from the residential land use counted method and the integrated method using both residential land use and the population in DAs and the integrated method using both residential land use and the population in DBs. These results provide references for selecting appropriate apportionment methods, which is the basis for transportation planning and policymaking.},
   author = {Hong Yao and Dong Mei Chen},
   doi = {10.1111/cag.12675},
   issn = {15410064},
   issue = {3},
   journal = {Canadian Geographer},
   keywords = {Toronto,comparaison,données liées aux déplacements,méthodes de répartition,zones d'analyse du trafic},
   month = {9},
   pages = {321-332},
   publisher = {John Wiley and Sons Inc},
   title = {Comparison of apportionment methods for assigning trip data to rezoned traffic analysis zones: A case study of Toronto, Canada},
   volume = {65},
   year = {2021},
}
@inproceedings{Deng2020,
   abstract = {Comparing the impact of different ways to divide traffic analysis zones (TAZs) on traffic assignments can provide a general method, which helps to find a better solution with less costs, for urban planning process and transportation policymaking. Previous literature has mostly studied foreign metropolitans but overlooks smaller-scaled regions. Thus, based on small and medium-sized cities, this paper uses quantitively methods to figure out the results of the impact that TAZs division on traffic assignment. Zhoukou (located in Henan province) is selected as the object. Using the Smith sampling model, the travel data table was obtained by GPS extraction with a questionnaire survey. Seven different ways to divide TAZs are considered and evaluated using TransCAD respectively. It is found that the effectiveness and accuracy of traffic assignment increase with the number of TAZs increasing, but there is a "threshold", which means the results would only fluctuate within a certain range if subdividing TAZs continually. However, when dividing TAZs with triangles and squares, traffic assignment results are similar, and they are superior to the results obtained by using traditional division ways with the same division number. Under the premise that the research area is not large and the number of divisions is limited, utilizing the grid method to divide TAZs can reduce the workload and acquire a preferable traffic prediction result. For the possible deviation, the reasons are discussed including the limitation of samples and software.},
   author = {Jihao Deng and Xiaohong Chen and Lu Ma},
   journal = {International Conference of Transportation Professionals},
   title = {Analysis of the Impact of Traffic Analysis Zones Division on Traffic Assignment},
   year = {2020},
}
@article{Sahu2020,
   abstract = {This paper contributes to the emerging literature on freight studies by identifying the optimal freight traffic analysis zone (FTAZ) system at which to conduct macro-level freight travel analysis. To arrive at the optimal scale, we develop alternate zone systems by grouping census wards with similar freight-related characteristics (industrial characteristics, commercial land use characteristics, locational characteristics and socio-demographic characteristics). The resultant zone systems are analysed at multiple geographic scales and the optimal scale of each zone system is determined by performing the Brown–Forsythe test. Results suggest that a 1:3 aggregation ratio (24–28 zones) is the optimal scale for Metropolitan FTAZs, whereas the publicly available ad-hoc zone system and prior literature on National FTAZs follow 1:10 aggregation. The study findings suggest that Metropolitan planning organizations need to reconsider their existing data collection strategy, consider a larger aggregation ratio and, by extension, adopt smaller zones to ensure that both local and global freight travel characteristics are captured in freight travel analyses.},
   author = {Prasanta K. Sahu and Aitichya Chandra and Agnivesh Pani and Bandhan Bandhu Majumdar},
   doi = {10.1080/03081060.2020.1780711},
   issn = {10290354},
   journal = {Transportation Planning and Technology},
   keywords = {Aggregation Ratio,Freight Data Collection,India,Optimal Scale,Traffic Analysis Zone (TAZ),Zone Design},
   pages = {620-637},
   publisher = {Routledge},
   title = {Designing freight traffic analysis zones for metropolitan areas: identification of optimal scale for macro-level freight travel analysis},
   year = {2020},
}
@inproceedings{Wang2014,
   abstract = {This paper presents a kind of constraint to ensure first-order contiguity of Traffic Analysis Zone delineation problem. Based on k-median facility location model, a 0-1 integer programming mathematical presentation of the problem, with objective of minimizing heterogeneity, is given. The proposed model is compared with other three ones in terms of model complexity and time consuming. The other three models have the characteristics of ensuring not only the first-order contiguity. It is concluded from the comparison that if zone number is smaller than certain value, the proposed model terminated without a feasible solution. Otherwise, the proposed model could obtain a satisfied solution within a reasonable time. An agglomerative hierarchical clustering based heuristic algorithm then is developed to deal with the non-solution situation. Finally, a case study shows the advantage of the proposed model for solving large scale problem. © 2014 IEEE.},
   author = {Linqing Wang and Jiafu Tang},
   doi = {10.1109/CCDC.2014.6852708},
   isbn = {9781479937066},
   journal = {26th Chinese Control and Decision Conference, CCDC 2014},
   keywords = {0-1 integer programming,contiguity constraint,traffic analysis zone},
   pages = {3103-3107},
   publisher = {IEEE Computer Society},
   title = {First-order contiguity constraint on Traffic Analysis Zone delineation problem},
   year = {2014},
}
@inproceedings{Jiang2017,
   abstract = {The result of road network traffic flow assignment varies with the use of different traffic analysis zone zoning methods. This paper develops a study on the effect of traffic analysis zone structure on road network flow assignment based on the traffic flow data of highways in Madrid, Spain. OD matrix estimation model and stochastic user equilibrium model are employed to study zoning effects and scale effects of modifiable area unit problem. The results indicate when designing traffic analysis zone. It is better to incorporate the population density information in order to obtain a good forecasting result and prove that the more zones the area is divided, the more accurate the forecasting result will be, but the promotion speed of accuracy slows down as the number of zones increases.},
   author = {Menglu Jiang and Minhua Shao and Lijun Sun},
   keywords = {administrative zones,number,population density,traffic analysis zone},
   title = {Study on the Effect of Traffic Analysis Zone Design on Road Network Flow Assignment: Based on City Madrid},
   year = {2017},
}
@inproceedings{Li2015,
   abstract = {In a four-step traffic planning model, the division of traffic analysis zones is primarily based on motorized traffic travel. Therefore, there is a need to study the none-motorized traffic zones. The paper defines the pedestrian traffic analysis zone, summarizes the principles of the pedestrian traffic zone division and proposes a division method based on pedestrian attracting/producing points. The division method includes three steps. Initially, the service radiuses of attracting/producing points are determined and unit zones are formed. Then, an envelope is established for the unit zones which have overlapping areas. Eventually, according to division principles, the boundary of the pedestrian traffic analysis zone is determined. A method of pedestrian travel intensity estimation of the traffic analysis zones is also proposed in this paper which is helpful for determining the pedestrian priority hierarchy and developing pedestrian priority measures. INTRODUCTION As urban transport problems could not be solved by massive construction of transport infrastructure, many countries and regions began to advocate non-motorized travel (pedestrian and non-motorized vehicles) and attach importance to non-motorized traffic planning. Division of traffic analysis zones is the basis of traffic planning. However, the division method of traffic analysis zone in the four step model is not suited for non-motorized traffic because of differences in travel characteristics and laws. The inadaptability presents in the following ways. The four step model describes travel distribution between different traffic analysis zones and often ignores inner travel. Moreover, to meet the survey purpose and precision, it often tried to cut down the number of traffic analysis zones by enlarging area in order to reduce the workload. Since non-motorized travel distance is relatively short, almost all the non-motorized travel occur in a single analysis zone. Besides, division of traffic analysis zones in the four step model is often consistent with administrative divisions. Nevertheless, current non-motorized traffic planning has been refined to district level and needs to analyze},
   author = {Ye Li and Yiran Zhang},
   title = {Research on Method of Pedestrian Traffic Analysis Zone Division and Traffic Intensity Estimation},
   year = {2015},
}
@article{Martínez2009,
   abstract = {This paper develops a comprehensive approach to the definition of transportation analysis zones (TAZ), and therein, presents a new methodology and algorithm for the definition of TAZ embedded in geographic information systems software, improves the base algorithm with several local algorithms, and comprehensively analyses the obtained results. The results obtained are then compared to these presently used in the transportation analysis process of the Lisbon Metropolitan Area. The proposed algorithm presents a new methodology for TAZ design based on a smoothed density surface of geocoded travel demand data. The algorithm aims to minimise the loss of information when moving from a continuous representation of the origin and destination of each trip to their discrete representations through zones, and focuses on the trade-off between the statistical precision, geographical error, and the percentage of intra-zonal trips of the resulting OD matrix. The results for the Lisbon Metropolitan Area case study suggest a significant improvement in OD matrix estimates compared to current transportation analysis practises based on administrative units. © Springer Science+Business Media, LLC. 2009.},
   author = {Luis M. Martínez and José Manuel Viegas and Elisabete A. Silva},
   doi = {10.1007/s11116-009-9214-z},
   issn = {00494488},
   issue = {5},
   journal = {Transportation},
   keywords = {GIS (geographic information systems),TAZ (transportation analysis zones),Transportation demand models,Transportation planning studies},
   pages = {581-599},
   title = {A traffic analysis zone definition: A new methodology and algorithm},
   volume = {36},
   year = {2009},
}
@article{Manout2021,
   abstract = {Most transport models rely on a discrete description of space, and are, therefore, subject to spatial aggregation bias. Spatial aggregation induces the use of centroid connectors and the omission of intrazonal trips in traffic assignment. This practice is shown to bias main traffic assignment outcomes, especially in spatially coarse models. To address these modeling errors, the literature suggests some solutions but no clear-cut conclusion on the contribution of these solutions is available. In the current research, we undergo a detailed investigation of the contribution of some of these modeling solutions in order to provide useful and practical recommendations to academics and policy makers. Different assignment strategies that are deemed to mitigate the impacts of spatial aggregation in traffic assignment are explored in different case studies. Findings from this research outline that demand-side assignment strategies outperform supply-side methods in addressing the spatial aggregation problem. The results also suggest that the inclusion of intrazonal demand in traffic assignment is not sufficient to overcome aggregation biases. The definition of connectors is also of importance.},
   author = {Ouassim Manout and Patrick Bonnel and François Pacull},
   doi = {10.1007/s11067-020-09505-6},
   issn = {15729427},
   issue = {1},
   journal = {Networks and Spatial Economics},
   keywords = {Intrazonal trips,Modifiable Areal Unit Problem (MAUP),Spatial aggregation,Traffic assignment,Transport modeling},
   month = {3},
   publisher = {Springer},
   title = {Spatial Aggregation Issues in Traffic Assignment Models},
   volume = {21},
   year = {2021},
}
@article{Manout2019,
   abstract = {In transportation modeling, intrazonal trips are frequently omitted during trip assignment. These trips are not assigned to the network because their origin and destination are in the same zone. However, in reality, intrazonal trips use the network and take up some of its capacity. This omission is due to the spatial aggregation problem. Omitting these short trips from assignment models affects the level of service of the network and biases the estimation of main assignment outcomes. The issue of intrazonal trips omission has received limited attention in transportation research. In this paper, we address the problem of ignoring intrazonal trips in traffic assignment models by applying a stochastic approach in order to characterize the statistical impact of their omission. Our results show that the omission of intrazonal trips has a significant impact on main assignment results. Network speeds, volumes and congestion levels vary significantly with the omission of intrazonal trips. The extent of this impact depends on the road’s category in the network hierarchy. As regards level of service, local streets are more sensitive to the omission of intrazonal trips than the primary network. These findings reveal the existence of a bias due to the omission of intrazonal trips in assignment models and raise doubts about the accuracy and reliability of assignment results from standard four step transport models especially when the spatial zoning is coarse.},
   author = {Ouassim Manout and Patrick Bonnel},
   doi = {10.1007/s11116-018-9951-y},
   issn = {15729435},
   issue = {6},
   journal = {Transportation},
   keywords = {Aggregation bias,Intrazonal trips,Modifiable Areal Unit Problem (MAUP),Transportation modeling},
   month = {12},
   pages = {2397-2417},
   publisher = {Springer},
   title = {The impact of ignoring intrazonal trips in assignment models: a stochastic approach},
   volume = {46},
   year = {2019},
}
@article{Wang2014,
   abstract = {A green transportation system composed of transit, busses and bicycles could be a significant in alleviating traffic congestion. However, the inaccuracy of current transit ridership forecasting methods is imposing a negative impact on the development of urban transit systems. Traffic Analysis Zone (TAZ) delineating is a fundamental and essential step in ridership forecasting, existing delineating method in four-step models have some problems in reflecting the travel characteristics of urban transit. This paper aims to come up with a Transit Traffic Analysis Zone delineation method as supplement of traditional TAZs in transit service analysis. The deficiencies of current TAZ delineating methods were analyzed, and the requirements of Transit Traffic Analysis Zone (TTAZ) were summarized. Considering these requirements, Thiessen Polygon was introduced into TTAZ delineating. In order to validate its feasibility, Beijing was then taken as an example to delineate TTAZs, followed by a spatial analysis of office buildings within a TTAZ and transit station departure passengers. Analysis result shows that the TTAZs based on Thiessen polygon could reflect the transit travel characteristic and is of in-depth research value. © 2014 by the authors.},
   author = {Shuwei Wang and Lishan Sun and Jian Rong and Zifan Yang},
   doi = {10.3390/su6041821},
   issn = {20711050},
   issue = {4},
   journal = {Sustainability (Switzerland)},
   keywords = {Ridership forecasting,Thiessen polygon,Traffic analysis zone,Urban transit},
   pages = {1821-1832},
   publisher = {MDPI},
   title = {Transit traffic analysis zone delineating method based on Thiessen polygon},
   volume = {6},
   year = {2014},
}
@article{Chen2019,
   abstract = {Information and communication technology development has yielded large-scale spatiotemporal datasets, such as mobile phone, automatic collection system, and car-hailing data, which have resulted in new opportunities to investigate urban transportation systems. However, few studies have focused on regional mobility patterns. This study presents a multistep method for exploring traffic analysis zone (TAZ)-based mobility patterns and the corresponding relations with local land use characteristics. Based on a large-scale mobile phone dataset from a major mobile phone operator in Beijing, we applied the K-means clustering algorithm to the hourly aggregated trip data to create clusters of TAZs with similar temporal mobility patterns. Land use characteristics were then derived and correlated with the temporal TAZ-based mobility patterns. Four clusters of TAZs with the similar patterns and intensities of urban activities during given time windows were identified. Land use indicators, such as residence and commercial and business area indicators, were correlated with specific temporal TAZ-based mobility patterns. The proposed multistep method could be applied in other cities to enrich relevant analyses and improve urban design and transportation planning.},
   author = {Yanyan Chen and Zheng Zhang and Tianwen Liang},
   doi = {10.3390/su11195452},
   issn = {20711050},
   issue = {19},
   journal = {Sustainability (Switzerland)},
   keywords = {Clustering,Logit model,Mobile phone data,Mobility patterns,Regional-oriented demand management policy},
   month = {10},
   publisher = {MDPI},
   title = {Assessing urban travel patterns: An analysis of traffic analysis zone-based mobility patterns},
   volume = {11},
   year = {2019},
}
@article{Viegas2009,
   abstract = {Transportation analysis is typically thought of as one kind of spatial analysis. A major point of departure in understanding problems in transportation analysis is the recognition that spatial analysis has some limitations associated with the discretization of space. Among them, modifiable areal units and boundary problems are directly or indirectly related to transportation planning and analysis through the design of traffic analysis zones (TAZs). The modifiable boundary and the scale issues should all be given specific attention during the specification of a TAZ because of the effects these factors exert on statistical and mathematical properties of spatial patterns (ie the modifiable areal unit problem - MAUP). The results obtained from the study of spatial data are not independent of the scale, and the aggregation effects are implicit in the choice of zonal boundaries. The delineation of zonal boundaries of TAZs has a direct impact on the reality and accuracy of the results obtained from transportation forecasting models. In this paper the MAUP effects on the TAZ definition and the transportation demand models are measured and analyzed using different grids (in size and in origin location). This analysis was developed by building an application integrated in commercial GIS software and by using a case study (Lisbon Metropolitan Area) to test its implementabiity and performance. The results reveal the conflict between statistical and geographic precision, and their relationship with the loss of information in the traffic assignment step of the transportation planning models. © 2009 Pion Ltd and its Licensors.},
   author = {José Manuel Viegas and L. Miguel Martínez and Elisabete A. Silva},
   doi = {10.1068/b34033},
   issn = {14723417},
   issue = {4},
   journal = {Environment and Planning B: Planning and Design},
   pages = {625-643},
   publisher = {Pion Limited},
   title = {Effects of the modifiable areal unit problem on the delineation of traffic analysis zones},
   volume = {36},
   year = {2009},
}
@report{Yang2007,
   abstract = {In order to predict and analyze the attributes of macro traffic flow on road network and micro traffic flow at intersection accurately during traffic impact assessment(TIA) ,a method of combining traffic volume distribution model with traffic simulation was developed. First, based on Geography Information System(GIS) ,Voronoi diagrams were used to traffic analysis zone(TAZ)partition, and the attribute data was also partitioned correspondingly.Then,multiplicative competitive interaction(MCI)model was adopted to estimate the new OD matrix. As a result, the output of traffic demand model can be input to micro traffic simulator direcdy to simulate and analyze the mi-cro traffic flow.Finally,a numeric test was done to show the validity and accuracy of the presented method. Key words: traffic impact assessment; traffic analysis zone partition; Voronoi diagram; MCI model 0 Introduction TIA analyzes in advance the land development impact on traffic. Since the end of 20th century, many countries (America, Europe, and Japan, etc.) have implemented TLA to forecast the induced traffic demand and analyze its impacts on urban transport network and especially on the surrounding roads.The aim of TLA is to find the problem and help the developer, road and traffic managers to solve the problems in advance .The common used solutions may be widening roads, setting dedicated lanes for left-turn or right-turn traffic , increasing signal control, and changing the location of entrances or exits. In the case of explicitly know that the supply cannot meet the demand even after efforts, the development will be reduced or cancelled. Recently, motorization and traffic demand growth rapidly in China, which makes cities to give up the method of matching supply to the demand but adopts the method of increasing supply as well as controlling demand.Many large cities (like Beijing, Shanghai, and Chongqing) have introduced TLA system to ask developers to analyze traffic impacts from their development, to understand the attributes of the increased traffic and the changes of service level in the surrounding roads, and to put forth counter measures. The key issue in TIA is to forecast traffic flows on future road network, which not only determines the tenability of the development but also is the base for road planning and traffic management. TLA should focus on traffic flow changes in both micro and macro levels because large-scale development causes not only traffic increment in surrounding area but also wide spread-impact. For example, construction of a hyper shopping center may change the distribution and modal split of shopping trip in the whole city. Therefore, the macro and micro attributes of traffic demand should be analyzed respectively. For macro analysis, effective method is 4-step traffic demand model,i.e. ,trip generation/attraction,modal split,trip distribution and assignment. Based on model outputs, service level of road network can be analyzed; while for micro analysis , traffic simulation technique is an effective tool .This tool can output the traffic flow of the intersection in surrounding road network, which can be used to analyze the service level, running speed, stop times and delay near the intersection. Moreover, the simulation technique can also be used to test the schemes of traffic management. When the scale of the development is small and its influence is limited , macro analysis is not important, while to the large scale one the macro and micro analysis are both necessary. Furthermore , because the traffic attributes in micro analysis come from macro traffic demand model, the combination of macro and micro analyses and matching their input and output in-Manuscript},
   author = {Zhong-Zhen Yang and Lu Wang and Chen Gang and ( Bfcb},
   issue = {2},
   journal = {Journal of Highway and Transportation Research and Development},
   pages = {80-83},
   title = {Method of Traffic Analysis Zone Partition for Traffic Impact Assessment*},
   volume = {2},
   year = {2007},
}
@article{Martinez2007,
   abstract = {In most transport planning studies, one of the first steps is the definition of a zoning scheme into which the study area is divided and the corresponding space is discretized. There are no clear rules on how to carry out this operation in an optimal way, and the dominating practice is to proceed on the basis of experience, trying to mix a certain degree of within-zone homogeneity and the convenience of using administrative borders as zone limits. The potential errors generated with this operation were examined, both at the statistical level when trip matrices are based on sampling and at the geographical level when all trips starting or ending in a zone are assumed to do so at its centroid. A set of quality criteria for a general zoning scheme and an algorithm that constructs a basic zoning on the basis of a sample of geo-referenced trip extreme points and improves it in successive steps according to those criteria are presented. A case study based on the mobility survey for the Lisbon, Portugal, metropolitan area illustrates those steps and the improvements achieved in each step. The magnitude of those improvements is significant and shows that more attention should definitely be given to this initial process in the transport planning studies.},
   author = {L. Miguel Martinez and José Manuel Viegas and Elisabete A. Silva},
   doi = {10.3141/1994-08},
   isbn = {9780309104203},
   issn = {03611981},
   issue = {1994},
   journal = {Transportation Research Record},
   pages = {58-65},
   title = {Zoning decisions in transport planning and their impact on the precision of results},
   year = {2007},
}
@article{Barthélemy2011,
   abstract = {Complex systems are very often organized under the form of networks where nodes and edges are embedded in space. Transportation and mobility networks, Internet, mobile phone networks, power grids, social and contact networks, and neural networks, are all examples where space is relevant and where topology alone does not contain all the information. Characterizing and understanding the structure and the evolution of spatial networks is thus crucial for many different fields, ranging from urbanism to epidemiology. An important consequence of space on networks is that there is a cost associated with the length of edges which in turn has dramatic effects on the topological structure of these networks. We will thoroughly explain the current state of our understanding of how the spatial constraints affect the structure and properties of these networks. We will review the most recent empirical observations and the most important models of spatial networks. We will also discuss various processes which take place on these spatial networks, such as phase transitions, random walks, synchronization, navigation, resilience, and disease spread. © 2010 Elsevier B.V.},
   author = {Marc Barthélemy},
   doi = {10.1016/j.physrep.2010.11.002},
   issn = {03701573},
   issue = {1-3},
   journal = {Physics Reports},
   keywords = {Geography,Graphs,Networks,Spatial properties,Statistical physics,Urban systems},
   month = {2},
   pages = {1-101},
   title = {Spatial networks},
   volume = {499},
   year = {2011},
}
@book{Sallan2015,
   abstract = {Linear programming is one of the most extensively used techniques in the toolbox of quantitative methods of optimization. One of the reasons of the popularity of linear programming is that it allows to model a large variety of situations with a simple framework. Furthermore, a linear program is relatively easy to solve. The simplex method allows to solve most linear programs efficiently, and the Karmarkar interior-point method allows a more efficient solving of some kinds of linear programming. The power of linear programming is greatly enhanced when came the opportunity of solving integer and mixed integer linear programming. In these models all or some of the decision variables are integers, respectively. In this book we provide a brief introduction to linear programming, together with a set of exercises that introduce some applications of linear programming. We will also provide an introduction to solve linear programming in R. For each problem a possible solution through linear programming is introduced, together with the code to solve it in R and its numerical solution.},
   author = {Jose M. Sallan and Oriol Lordan and Vicenc Fernandez},
   doi = {10.3926/oss.20},
   journal = {Modeling and Solving Linear Programming with R},
   month = {9},
   publisher = {OmniaScience},
   title = {Modeling and Solving Linear Programming with R},
   year = {2015},
}
@generic{Joo2020,
   abstract = {The advent of miniaturized biologging devices has provided ecologists with unprecedented opportunities to record animal movement across scales, and led to the collection of ever-increasing quantities of tracking data. In parallel, sophisticated tools have been developed to process, visualize and analyse tracking data; however, many of these tools have proliferated in isolation, making it challenging for users to select the most appropriate method for the question in hand. Indeed, within the r software alone, we listed 58 packages created to deal with tracking data or ‘tracking packages’. Here, we reviewed and described each tracking package based on a workflow centred around tracking data (i.e. spatio-temporal locations (x, y, t)), broken down into three stages: pre-processing, post-processing and analysis, the latter consisting of data visualization, track description, path reconstruction, behavioural pattern identification, space use characterization, trajectory simulation and others. Supporting documentation is key to render a package accessible for users. Based on a user survey, we reviewed the quality of packages' documentation and identified 11 packages with good or excellent documentation. Links between packages were assessed through a network graph analysis. Although a large group of packages showed some degree of connectivity (either depending on functions or suggesting the use of another tracking package), one third of the packages worked in isolation, reflecting a fragmentation in the r movement-ecology programming community. Finally, we provide recommendations for users when choosing packages, and for developers to maximize the usefulness of their contribution and strengthen the links within the programming community.},
   author = {Rocío Joo and Matthew E. Boone and Thomas A. Clay and Samantha C. Patrick and Susana Clusella-Trullas and Mathieu Basille},
   doi = {10.1111/1365-2656.13116},
   issn = {13652656},
   issue = {1},
   journal = {Journal of Animal Ecology},
   keywords = {biologging,movement ecology,r project for statistical computing,spatial,tracking data},
   month = {1},
   pages = {248-267},
   pmid = {31587257},
   publisher = {Blackwell Publishing Ltd},
   title = {Navigating through the r packages for movement},
   volume = {89},
   year = {2020},
}
@generic{Quezada2019,
   abstract = {The association between geographical distribution of facilities and accessibilities by different transport modes shows a several spatial inequities by motilities in the Los Ángeles (Chile). This research analyzed the accessibility to collective facilities in transport modes throw quantitative indicators, used network analysis. Travel data are used in private, public and walking modes of the Origin-Destination survey (2004). The results show sharp spatial differences between the center and periphery in Los Ángeles. In fact, population at the city center has high accessibility levels, concentrating greatest opportunities. In contrast, the population at the city's periphery must travel long distances to access, especially in walking. The results increase our understanding about the distribution of opportunities, comparing the opportunity to access for different groups, and the role of transport in mobilities of midsize cities of latinamerican with a relevant center.},
   author = {Carolina Rojas Quezada and Marcela Martínez Bascuñán and Helen De La Fuente Contreras and Andrés Schäfer Faulbaum and Felipe Aguilera Saéz and Gloria Fuentes Me-Lla and Consuelo Peyrín Fuentes and Juan Carrasco Montagnaancas Cruz},
   doi = {10.5209/aguc.64682},
   issn = {19882378},
   issue = {1},
   journal = {Anales de Geografia de la Universidad Complutense},
   keywords = {Accessibility,Los Ángeles,Mid-size cities,Mobility,Network Analysis,Transport modes},
   pages = {177-200},
   publisher = {Universidad Compultense Madrid},
   title = {Accessibility to equipment according to mobility and modes of transport in an average city, Los Angeles, Chile},
   volume = {39},
   year = {2019},
}
@thesis{Alberto2012,
   author = {Julián Alberto and Arellana Ochoa and Juan De Dios and Ortúzar Salas and Luis Ignacio and Rizzi Campanella},
   title = {MODELOS DE ELECCIÓN DE LA HORA DE INICIO DE VIAJE},
   year = {2012},
}
@report{Blum2018,
   author = {Avrim Blum and John Hopcroft and Ravindran Kannan},
   title = {Foundations of Data Science *},
   year = {2018},
}
@article{Tsekeris2011,
   abstract = {The main purpose of this paper is to comprehensively explore and productively overview the growing research field of demand forecasting in transport. In this analytic context, it seeks to describe, critically discuss and fruitfully elaborate on relevant mechanisms and models of demand forecasting, as well as on the particular development and implementation of systematic (or system-wide) approaches. The overview of various theoretical and methodological developments in current prediction models eventually advocates the use of consumer demand models (of dynamic character) to predict demand shares among alternative modes of transport.},
   author = {Theodore Tsekeris and Charalambos Tsekeris},
   doi = {10.1080/1331677X.2011.11517446},
   issn = {1331677X},
   issue = {1},
   journal = {Ekonomska Istrazivanja},
   keywords = {Consumer demand,Household expenditure,Intermodal competition,Traffic forecasts,Transport models},
   pages = {82-94},
   publisher = {Faculty of Economics and Tourism 'Dr. Mijo Mirkovic'},
   title = {Demand forecasting in transport: Overview and modeling advances},
   volume = {24},
   year = {2011},
}
@article{Raadsen2020,
   abstract = {In this study we provide a comprehensive review of the existing literature on (dis)aggregation and decomposition methods in traffic assignment and classify them based on their characteristics. The study takes on two different perspectives. First, we explore existing methods and relate them to one or more traffic assignment components. It is found that there exists a clear separation between a demand modelling point of view, i.e., travel demand and (geographical) zoning on the one hand, and supply modelling-oriented methods, i.e. network topology and network loading, on the other. Further, we explore the existing literature on the interface between demand and supply, i.e., connector and centroid placement which is to be considered a special type of aggregation. It is found this aspect of traffic assignment has received relatively little attention in this context, even though it is shown to be of significant impact on modelling results. The second perspective in this study places the discussed aggregation methodologies in the broader perspective of clustering procedures. We do not necessarily explore clustering methods as such but mainly look at the classification of different types of clustering methods which can be projected onto the traffic assignment domain and aggregation procedures in particular. It is shown that most existing methods can be classified as supervised – or classification based – clustering procedures while relatively few studies explore other known approaches such as semi-supervised or unsupervised clustering techniques. Lastly, we discuss how aggregation techniques could be deployed to construct multi-scale modelling environments. There is however a lack of methodology to construct such models consistently. Findings are presented via an objective classification framework for existing (dis)aggregation and decomposition methods.},
   author = {Mark P.H. Raadsen and Michiel C.J. Bliemer and Michael G.H. Bell},
   doi = {10.1016/j.trb.2020.06.008},
   issn = {01912615},
   journal = {Transportation Research Part B: Methodological},
   month = {9},
   pages = {199-223},
   publisher = {Elsevier Ltd},
   title = {Aggregation, disaggregation and decomposition methods in traffic assignment: historical perspectives and new trends},
   volume = {139},
   year = {2020},
}
@article{Arambepola2020,
   abstract = {Disaggregation regression has become an important tool in spatial disease mapping for making fine-scale predictions of disease risk from aggregated response data. By including high resolution covariate information and modelling the data generating process on a fine scale, it is hoped that these models can accurately learn the relationships between covariates and response at a fine spatial scale. However, validating these high resolution predictions can be a challenge, as often there is no data observed at this spatial scale. In this study, disaggregation regression was performed on simulated data in various settings and the resulting fine-scale predictions are compared to the simulated ground truth. Performance was investigated with varying numbers of data points, sizes of aggregated areas and levels of model misspecification. The effectiveness of cross validation on the aggregate level as a measure of fine-scale predictive performance was also investigated. Predictive performance improved as the number of observations increased and as the size of the aggregated areas decreased. When the model was well-specified, fine-scale predictions were accurate even with small numbers of observations and large aggregated areas. Under model misspecification predictive performance was significantly worse for large aggregated areas but remained high when response data was aggregated over smaller regions. Cross-validation correlation on the aggregate level was a moderately good predictor of fine-scale predictive performance. While the simulations are unlikely to capture the nuances of real-life response data, this study gives insight into the effectiveness of disaggregation regression in different contexts.},
   author = {Rohan Arambepola and Tim C D Lucas and Anita K Nandi and Peter W Gething and Ewan Cameron},
   month = {5},
   title = {A simulation study of disaggregation regression for spatial disease mapping},
   url = {http://arxiv.org/abs/2005.03604},
   year = {2020},
}
@article{Mimmack2000,
   abstract = {Cluster analysis is a technique frequently used in climatology for grouping cases to define classes (synoptic types or climate regimes, for example), or for grouping stations or grid points to define regions. Cluster analysis is based on some form of distance matrix, and the most commonly used metric in the climatological field has been Euclidean distances. Arguments for the use of Euclidean distances are in some ways similar to arguments for using a covariance matrix in principal components analysis: the use of the metric is valid if all data are measured on the same scale. When using Euclidean distances for cluster analysis, however, the additional assumption is made that all the variables are uncorrelated, and this assumption is frequently ignored. Two possible methods of dealing with the correlation between the variables are considered: performing a principal components analysis before calculating Euclidean distances, and calculating Mahalanobis distances using the raw data. Under certain conditions calculating Mahalanobis distances is equivalent to calculating Euclidean distances from the principal components. It is suggested that when cluster analysis is used for defining regions, Mahalanobis distances are inappropriate, and that Euclidean distances should be calculated using the unstan-dardized principal component scores based on only the major principal components.},
   author = {Gillian M Mimmack and Simon J Mason and Jacqueline S Galpin},
   title = {NOTES AND CORRESPONDENCE Choice of Distance Matrices in Cluster Analysis: Defining Regions},
   url = {http://journals.ametsoc.org/jcli/article-pdf/14/12/2790/3775869/1520-0442},
   year = {2000},
}
@article{Hicks2019,
   abstract = {The data revolution has led to an increased interest in the practice of data analysis. For a given problem, there can be significant or subtle differences in how a data analyst constructs or creates a data analysis, including differences in the choice of methods, tooling, and workflow. In addition, data analysts can prioritize (or not) certain objective characteristics in a data analysis, leading to differences in the quality or experience of the data analysis, such as an analysis that is more or less reproducible or an analysis that is more or less exhaustive. However, data analysts currently lack a formal mechanism to compare and contrast what makes analyses different from each other. To address this problem, we introduce a vocabulary to describe and characterize variation between data analyses. We denote this vocabulary as the elements and principles of data analysis, and we use them to describe the fundamental concepts for the practice and teaching of creating a data analysis. This leads to two insights: it suggests a formal mechanism to evaluate data analyses based on objective characteristics, and it provides a framework to teach students how to build data analyses.},
   author = {Stephanie C. Hicks and Roger D. Peng},
   month = {3},
   title = {Elements and Principles for Characterizing Variation between Data Analyses},
   url = {http://arxiv.org/abs/1903.07639},
   year = {2019},
}
@article{Naimi2019,
   abstract = {Research on spatial data analysis has developed a number of local indicators of spatial association (LISA), which allow exploration of local patterns in spatial data. These include local Moran's [Formula presented] and local Geary's [Formula presented], as well as [Formula presented] and [Formula presented] that can be used for continuous or interval variables only. Despite numerous situations where qualitative (nominal/categorical) variables are encountered, few attempts have been devoted to the development of methods to explore the local spatial pattern in categorical data. To our knowledge, there is no indicator of local spatial association that can be used for both continuous and categorical data at the same time. In this paper, we propose a new local indicator of spatial association, called the entropy-based local indicator of spatial association (ELSA), that can be used for both categorical and continuous spatial data. ELSA quantifies the degree of spatial association of a variable at each location relative to the same variable at the neighbouring locations. This indicator simultaneously incorporates both spatial and attribute aspects of spatial association into account. The values of ELSA vary between 0 and 1, which denote highest and lowest spatial association, respectively. We compare ELSA to existing statistics such as Local Moran's I and test the power and size of the new statistic. We also introduce the ”entrogram” a novel approach for exploring the global spatial structure within the entire area (like a variogram). This study showed that the ELSA is consistent and robust, and is therefore suitable for applications in a wide range of disciplines. The ELSA algorithm is made available as an R-package (elsa).},
   author = {Babak Naimi and Nicholas A.S. Hamm and Thomas A. Groen and Andrew K. Skidmore and Albertus G. Toxopeus and Sara Alibakhshi},
   doi = {10.1016/j.spasta.2018.10.001},
   issn = {22116753},
   journal = {Spatial Statistics},
   keywords = {LISA,Local statistic,Non-stationary,Spatial autocorrelation,Spatial dependency,Variogram},
   month = {3},
   pages = {66-88},
   publisher = {Elsevier B.V.},
   title = {ELSA: Entropy-based local indicator of spatial association},
   volume = {29},
   year = {2019},
}
@article{Stathopoulos2004,
   abstract = {The problem of updating dynamic origin-destination (O-D) matrices by exploiting a long-term time series of link traffic counts in large-scale transportation networks without the need for surveys or census data is investigated. Different time-recursive mechanisms for analysis of these data to enhance the performance of the models currently used to synthesize within-day dynamic O-D matrices are suggested. The efficiency of the proposed procedure is investigated with respect to different formulations and related solution algorithms (based on entropy maximization and generalized least-squares). The impacts of different assumptions on model performance are also examined. These include the length of the time scale in which the flow information is updated and the selection of the weekday for which the flow information is collected. The results of the statistical analysis and the model performance measures demonstrate that the proposed time-recursive procedure for an information updating period of 2 years can produce an improved prior O-D matrix that may significantly enhance the subsequent updating of dynamic O-D matrices corresponding to a series of days of the week. The updating of origin-destination (O-D) trip matrices by use of link traffic count data, usually referred to as O-D matrix synthesis, can provide valuable information about the demand for trip interchange between zones or nodes (intersections) in the transportation network. The low cost and effort associated with the automated collection of these data have resulted in the widespread use of models for updating O-D matrices, which are extremely useful in transportation planning and traffic operations. But, a prior O-D matrix is typically used as a target or seed to guide the procedure used to solve these models. Comparisons of several dynamic models of O-D matrix synthesis-models that estimate the temporal pattern of O-D demand on the basis of a time series of links counts over successive time intervals in a given study period-have demonstrated that they can produce link flow solutions significantly superior to those obtained by dynamically assigning the prior O-D matrix onto the network (1). A review of the models used for the dynamic assignment of the O-D matrix onto the network, known as dynamic traffic assignment models, is provided elsewhere (2). However, a credible prior O-D matrix capable of adequately representing the actual O-D demand in the study period is not available in most urban areas. This is because of the costs involved with regularly conducting travel surveys or collecting socioeconomic or census data to estimate a prior O-D matrix by use of a transportation planning model. This problem can lead to the reduced performance of the O-D matrix updating, particularly as the time between the study period and the period in which the prior O-D matrix was estimated increases. The model performance can be described by the extent to which it can produce an O-D matrix close to the prior one (or the one most likely to exist) while sufficiently replicating the measured link volumes. The problem of prior O-D demand information has hitherto been investigated only for the case of static (time-uniform) O-D matrix synthesis by use of standard census data (3). On the contrary, the corresponding problem for the case of dynamic O-D matrix synthesis has been largely restricted to the treatment of the dynamics underlying the within-day O-D demand information corresponding to previous time intervals and estimated by using some recursive (Bayesian updating) model (4). Nonetheless, the latter method entails a considerable computational load that may render it impractical for applications on realistically sized urban networks and related online traffic operations. In addition, such a method does not consider the possible impacts of the long-term systematic changes of prior demand information, for example, because of land use changes, on the dynamic O-D matrix synthesis. This paper presents a cost-efficient and effective procedure that can be used to enhance the performance of dynamic O-D matrix updating by the use of a long-term time series of link traffic counts as the sole data source. The applicability of the proposed procedure to real-world urban networks is demonstrated by a relevant case study of the central part of the network of the greater Athens area in Greece. The next section presents two alternative formulations and solution procedures for the problem of dynamic O-D matrix synthesis. The dynamic traffic assignment model with which the models used to synthesize dynamic O-D matrices are combined is then described. Different mechanisms for incorporation of the long-term dynamics of O-D information into the suggested models and a description of the case study network are provided. The results of simulation tests undertaken to investigate the impacts of these mechanisms on the model performance measures, including the effects of different time scales, weekdays, and solution procedures, are presented. Moreover, a statistical analysis and interpretation of the results are carried out. Finally, conclusions drawn from the study results are presented. MODELS OF DYNAMIC O-D MATRIX SYNTHESIS The problem of dynamic O-D matrix synthesis is first described on the basis of the maximum-entropy (ME) formulation (5). Consider a network that includes N traffic zones from and to which vehicular},
   author = {Antony Stathopoulos and Theodore Tsekeris},
   journal = {Transportation Research Record: Journal of the Transportation Research},
   pages = {159-166},
   title = {Enhanced Dynamic Origin-Destination Matrix Updating with Long-Term Flow Information},
   volume = {1882},
   year = {2004},
}
@article{Nolè2015,
   abstract = {Up to nowadays, satellite data have become increasingly available, thus offering a low cost or even free of charge unique tool, with a great potential for quantitative assessment of urban expansion and urban sprawl, as well as for monitoring of land use changes and soil consumption. This growing observational capacity has also highlighted the need for research efforts aimed at exploring the potential offered by data processing methods and algorithms, in order to exploit as much as possible this invaluable space-based data source.The work herein presented concerns an application study on the process of urban sprawl conducted with the use of satellite ASTER data. The selected test site is highly significant, being it a coastal zone (with the presence of sand and rocks) characterized by a fragmented ecosystem and small towns, with an increasing rate of urbanization and soil consumption. In order to produce synthetic maps of urban areas, ASTER images were classified using two automatic classifiers, Maximum Likelihood (MLC) and Support Vector Machines (SVMs) applied by changing setting parameters, with the aim to compare their respective performances in terms of robustness, speed and accuracy. All process steps have been developed integrating Geographical Information System and Remote Sensing, and adopting free and open source software.Results pointed out that the SVM classifier with RBF kernel was generally the best choice (with accuracy higher than 90%) among all the configurations compared, and the use of multiple bands globally improves classification. One of the critical elements found in this case study is given by the presence of sand and sand mixed with rocks. The use of different configurations for the SVMs, i.e. different kernels and values of the setting parameters, allowed us to calibrate the classifier also to cope with a specific need, as in our case, to achieve a reliable discrimination of sand from urban area.},
   author = {Gabriele Nolè and Beniamino Murgante and Giuseppe Calamita and Antonio Lanorte and Rosa Lasaponara},
   doi = {10.1016/j.ecoinf.2014.05.005},
   issn = {15749541},
   issue = {P2},
   journal = {Ecological Informatics},
   keywords = {Open source software,Planning,SVM,Satellite data,Sustainability,Urban sprawl},
   month = {3},
   pages = {151-161},
   publisher = {Elsevier B.V.},
   title = {Evaluation of urban sprawl from space using open source technologies},
   volume = {26},
   year = {2015},
}
@article{Burlacu2020,
   abstract = {The city is an "organism" that converts raw materials, energy and information, reacts and changes through self-organization and especially through anthropic-conscious organization. The "urban" character of the space therefore implies clear attributes, with obvious effects on its organization: low density, adequate technical and construction equipment, differentiation of functional areas corresponding to the multitude of functions accumulated over time, etc. The characteristics of the urban space itself change: the density of population and constructions increases, the density of investments per unit area increases considerably, a true "market" of labor is formed, in which demand and supply determine a certain professional, but also social mobility; over time, there is even a certain segregation of habitat (by social class or ethnic origin), activities and jobs. The urban zoning with a functional character is an action destined for the urban remodeling, by delimiting the functional areas within the urban space and constitutes a major requirement of the contemporary urbanism. The objective of this article is to present the recent theories and models of delimitation of functional areas in the urban space that allow the identification of functional mechanisms for establishing the functional areas, taking into account, as far as possible, the dominant activity of the territory.},
   author = {Sorin Burlacu and Alexandru Gavrilă and Ioana Maria Popescu and Svetlana Platagea Gombos and Petrut Cristian},
   doi = {10.24818/RMCI.2020.1.44},
   issue = {1},
   keywords = {R58,functional zoning,models,theories JEL classification: R12,urban space},
   pages = {44},
   title = {Theories and Models of Functional Zoning in Urban Space},
   volume = {21},
   year = {2020},
}
@article{Heppenstall2021,
   abstract = {Despite reaching a point of acceptance as a research tool across the geographical and social sciences, there remain significant methodological challenges for agent-based models. These include recognizing and simulating emergent phenomena, agent representation, construction of behavioral rules, and calibration and validation. While advances in individual-level data and computing power have opened up new research avenues, they have also brought with them a new set of challenges. This article reviews some of the challenges that the field has faced, the opportunities available to advance the state-of-the-art, and the outlook for the field over the next decade. We argue that although agent-based models continue to have enormous promise as a means of developing dynamic spatial simulations, the field needs to fully embrace the potential offered by approaches from machine learning to allow us to fully broaden and deepen our understanding of geographical systems.},
   author = {Alison Heppenstall and Andrew Crooks and Nick Malleson and Ed Manley and Jiaqi Ge and Michael Batty},
   doi = {10.1111/gean.12267},
   issn = {15384632},
   issue = {1},
   journal = {Geographical Analysis},
   month = {1},
   pages = {76-91},
   publisher = {Blackwell Publishing Inc.},
   title = {Future Developments in Geographical Agent-Based Models: Challenges and Opportunities},
   volume = {53},
   year = {2021},
}
@article{Baray2020,
   abstract = {This article introduces a new model which aims at spatially optimizing the price of a product or service by considering supply and demand features, including their geographical location. Introducing the concept of a geomarketing-mix, factorial analysis and fuzzy clustering can be employed to automatically detect business and strategic opportunities. The method is applied to the French secondhand car market. By so doing, it is possible, first, to identify geographic areas that are typical of a certain supply and, second, to specify the optimal prices and types of vehicles for sale in these areas in view of a given marketing strategy.},
   author = {Jérôme Baray and Martine Pelé},
   doi = {10.1177/2051570720906077},
   issn = {20515707},
   issue = {3},
   journal = {Recherche et Applications en Marketing},
   keywords = {algorithm pricing,artificial intelligence,big data in marketing,geomarketing-mix,geopricing,morphological analysis,optimized location models,pricing strategy,spatial clustering},
   month = {9},
   pages = {29-51},
   publisher = {SAGE Publications Ltd},
   title = {A new geographical pricing model within the principle of geomarketing-mix},
   volume = {35},
   year = {2020},
}
@article{Oshan2019,
   abstract = {Geographically weighted regression (GWR) is a spatial statistical technique that recognizes that traditional ‘global’ regression models may be limited when spatial processes vary with spatial context. GWR captures process spatial heterogeneity by allowing effects to vary over space. To do this, GWR calibrates an ensemble of local linear models at any number of locations using ‘borrowed’ nearby data. This provides a surface of location-specific parameter estimates for each relationship in the model that is allowed to vary spatially, as well as a single bandwidth parameter that provides intuition about the geographic scale of the processes. A recent extension to this framework allows each relationship to vary according to a distinct spatial scale parameter, and is therefore known as multiscale (M)GWR. This paper introduces mgwr, a Python-based implementation of MGWR that explicitly focuses on the multiscale analysis of spatial heterogeneity. It provides novel functionality for inference and exploratory analysis of local spatial processes, new diagnostics unique to multi-scale local models, and drastic improvements to efficiency in estimation routines. We provide two case studies using mgwr, in addition to reviewing core concepts of local models. We present this in a literate programming style, providing an overview of the primary software functionality and demonstrations of suggested usage alongside the discussion of primary concepts and demonstration of the improvements made in mgwr.},
   author = {Taylor M. Oshan and Ziqi Li and Wei Kang and Levi J. Wolf and A. Stewart Fotheringham},
   doi = {10.3390/ijgi8060269},
   issn = {22209964},
   issue = {6},
   journal = {ISPRS International Journal of Geo-Information},
   keywords = {Gwr,Heterogeneity,Mgwr,Multiscale,Scale,Spatial statistics},
   month = {6},
   publisher = {MDPI AG},
   title = {MGWR: A python implementation of multiscale geographically weighted regression for investigating process spatial heterogeneity and scale},
   volume = {8},
   year = {2019},
}
@article{Chmielewski2020,
   abstract = {Planning the development of transport systems, as well as assessing the effects of investment activities in the field of spatial development requires the use of appropriate IT tools enabling an objective assessment of investment intentions. In the field of transport analysis, one such tool is a transport demand model. Reproduction of transport-related processes is the main role of such transport demand model. This applies to both the transport of people and goods, and includes both residential travel and visitors travelling to and within the study area. The description of the process of creation and implementation of transport demands is usually based on the assumptions in the field of places of generation and absorption of travel - i.e. sources and destinations of travel. The generalization of the mathematical description of this phenomenon introduced the concept of transport zones, which are separated homogeneous areas of the study area, as sources and destinations of trips. Practice in the construction and use of transport models indicates that the problem of  defining transport zones requires further investigation. Increasingly extensive transport infrastructure data collected in open databases (such as OpenStreets) are encouraging a change in the approach to the problems of constructing transport zones. The current solutions are characterized by a high level of generalization of sources and destinations rather than detailed transport analysis. This article presents the author’s method of dividing the study areas into transport zones based on a uniform hexagonal system, explaining the basic assumptions and evaluating the pros and cons of this proposed system.
 Keywords: Transport, Demand models, Algorithms},
   author = {Jacek Chmielewski and Jan Kempa},
   doi = {10.18502/keg.v5i6.7025},
   journal = {KnE Engineering},
   month = {6},
   publisher = {Knowledge E},
   title = {Hexagonal Zones in Transport Demand Models},
   year = {2020},
}
@article{Smith2009,
   abstract = {This article shows that, for both spatial lag and spatial error models with strongly connected weight matrices, maximum likelihood estimates of the spatial dependence parameter are necessarily biased downward. In addition, this bias is shown to be present in general Moran tests of spatial dependency. Thus, positive dependencies may often fail to be detected when weight matrices are strongly connected. The analysis begins with a detailed examination of downward bias for the extreme case of maximally connected weight matrices. Results for this case are then extended by continuity to a broader range of (appropriately defined) strongly connected matrices. Finally , a simulated numerical example is presented to illustrate some of the practical consequences of these biases.},
   author = {Tony E Smith},
   journal = {Geographical Analysis},
   pages = {307-332},
   title = {Estimation Bias in Spatial Models with Strongly Connected Weight Matrices},
   volume = {41},
   year = {2009},
}
@article{Acheampong2015,
   abstract = {The aim of this review paper is to provide comprehensive and up-to-date material for both researchers and practitioners interested in land-use-transport interaction (LUTI) modeling. The paper brings together some 60 years of published research on the subject. The review discusses the dominant theoretical and conceptual propositions underpinning research in the field and the existing operational LUTI modeling frameworks as well as the modeling methodologies that have been applied over the years. On the basis of these, the paper discusses the challenges, on-going progress and future research directions around the following thematic areas: 1) the challenges imposed by disaggregation—data availability, computation time, stochastic variation and output uncertainty; 2) the challenges of and progress in integrating activity-based travel demand models into LUTI models; 3) the quest for a satisfactory measure of accessibility; and 4) progress and challenges toward integrating the environment into LUTI models.},
   author = {Ransford A. Acheampong and Elisabete A. Silva},
   doi = {10.5198/jtlu.2015.806},
   issn = {19387849},
   issue = {3},
   journal = {Journal of Transport and Land Use},
   keywords = {Activity-based approach,Four-step model,Land-use,Micro-simulation,Stochasticity,Transportation,Uncertainty},
   pages = {11-38},
   publisher = {University of Minnesota},
   title = {Land use–transport interaction modeling: A review of the literature and future research directions},
   volume = {8},
   year = {2015},
}
@inproceedings{Lebedeva2020,
   abstract = {The analysis of transport accessibility is a standard task requiring the search for the optimal solution, the solution of which is necessary for the harmonious development of the urban environment in general, and the effective organization of the transportation process in particular. The article discusses the indicators necessary for determining transport accessibility based on analysis of the urban transport system and calculation methods using geographical information systems. The main parameter is time-based accessibility from the central part of the city to other transport zones. To determine the rank of the transport zone, the following statistical characteristics are required: road network density in urban areas; a number of jobs, a number of equipped parking spaces; the number of objects of gravity in transport zones. A decision support system based on geographic information systems can be carried out by two methods: the choice of a relatively ideal solution and simple additive weighing. Analysis of transport zones can improve the quality of statistical data on urban transport medium. The article presents the models, the use which is necessary for efficient operation of urban transport, as well as indicators necessary for the stable functioning of the infrastructure. It can be integrated into planning systems and sustainable development of urban transport and planning.},
   author = {O. A. Lebedeva and J. O. Poltavskaya},
   doi = {10.1088/1742-6596/1615/1/012010},
   issn = {17426596},
   issue = {1},
   journal = {Journal of Physics: Conference Series},
   month = {8},
   publisher = {IOP Publishing Ltd},
   title = {Analysis of city transport network based on geoinformation systems in transport zones of industrial city},
   volume = {1615},
   year = {2020},
}
@article{Grubesic2008,
   abstract = {The use of zip codes for spatial, demographic, and socio-economic analysis is growing. As of August 2005, 193 articles were indexed by "zip code" in the Social Sciences Citation Index, while 386 were indexed in PubMed. All of these articles were published since 1989. While the treatment of zip codes as units of analysis varies widely in epidemiology, marketing, geography, and the socio-economic planning sciences, there are a number of common "errors" that could be avoided if analysts retained a better understanding of zip code characteristics. The purpose of this paper is to outline the problems and prospects of utilizing zip codes for spatial analysis. Issues associated with spatial contiguity, data aggregation, and boundary definitions are addressed. Results suggest that, although zip codes are not the most robust spatial units of analysis available, they retain a modest degree of utility for specialized applications. Recommendations for future research regarding zip codes and their use in socio-economic applications are offered. © 2006 Elsevier Ltd. All rights reserved.},
   author = {Tony H. Grubesic},
   doi = {10.1016/j.seps.2006.09.001},
   issn = {00380121},
   issue = {2},
   journal = {Socio-Economic Planning Sciences},
   keywords = {GIS,Spatial analysis,Zip code},
   month = {6},
   pages = {129-149},
   title = {Zip codes and spatial analysis: Problems and prospects},
   volume = {42},
   year = {2008},
}
@article{Langton2021,
   abstract = {The visualisation of spatial information is a powerful tool for researchers in urban analytics seeking to convey their findings to the wider research community and the public in an accessible way. Yet, even the most well-intentioned cartographer may introduce misrepresentation by mapping irregularly shaped and sized areas. This paper explores the extent to which different methods of visualising area-based data can remedy (or exacerbate) this misrepresentation by presenting results from a crowdsourced survey. Data from the 2016 European Union referendum at Local Authority level in England are visualised using four alternative methods (balanced cartogram, hexogram, hexagonal grid, square grid) and compared to a traditional choropleth map, in terms of people’s understanding of the authors’ intended message, through a crowdsourced survey questionnaire. Results indicate that mapping out original boundaries can introduce misrepresentation, which can be mitigated by using balanced cartograms and hexograms to improve the accuracy of visualisations.},
   author = {Samuel H. Langton and Reka Solymosi},
   doi = {10.1177/2399808319873923},
   issn = {23998091},
   issue = {2},
   journal = {Environment and Planning B: Urban Analytics and City Science},
   keywords = {Brexit,Visualisation,cartogram,hexogram},
   month = {2},
   pages = {348-357},
   publisher = {SAGE Publications Ltd},
   title = {Cartograms, hexograms and regular grids: Minimising misrepresentation in spatial data visualisations},
   volume = {48},
   year = {2021},
}
@article{Cao2020,
   author = {Kai Cao and Wenwen Li and Richard Church},
   doi = {10.1177/2399808320935269},
   issn = {23998091},
   issue = {6},
   journal = {Environment and Planning B: Urban Analytics and City Science},
   month = {7},
   pages = {941-947},
   publisher = {SAGE Publications Ltd},
   title = {Big data, spatial optimization, and planning},
   volume = {47},
   year = {2020},
}
@book{Wikle2021,
   abstract = {Introduction to spatio-temporal statistics -- Exploring spatio-temporal data -- Spatio-temporal statistical models -- Descriptive spatio-temporal statistical models -- Dynamic spatio-temporal models -- Evaluating spatio-temporal statistical models -- Pergimus (epilogue) -- Appendices.},
   author = {Christopher K. Wikle and Andrew Zammit-Mangion and Noel A. C. Cressie},
   isbn = {9781138711136},
   pages = {380},
   title = {Spatio-temporal statistics with R},
}
@article{Suesse2017,
   abstract = {Maximum likelihood (ML) estimation with spatial econometric models is a long-standing problem that finds application in several areas of economic importance. The problem is particularly challenging in the presence of missing data, since there is an implied dependence between all units, irrespective of whether they are observed or not. Out of the several approaches adopted for ML estimation in this context, that of LeSage and Pace [Models for spatially dependent missing data. J Real Estate Financ Econ. 2004;29(2):233–254] stands out as one of the most commonly used with spatial econometric models due to its ability to scale with the number of units. Here, we review their algorithm, and consider several similar alternatives that are also suitable for large datasets. We compare the methods through an extensive empirical study and conclude that, while the approximate approaches are suitable for large sampling ratios, for small sampling ratios the only reliable algorithms are those that yield exact ML or restricted ML estimates.},
   author = {Thomas Suesse and Andrew Zammit-Mangion},
   doi = {10.1080/00949655.2017.1286495},
   issn = {15635163},
   issue = {9},
   journal = {Journal of Statistical Computation and Simulation},
   keywords = {EM algorithm,missing data,spatial autoregressive models,spatial-errors models},
   month = {6},
   pages = {1767-1786},
   publisher = {Taylor and Francis Ltd.},
   title = {Computational aspects of the EM algorithm for spatial econometric models with missing data},
   volume = {87},
   year = {2017},
}
@article{Suesse2018,
   abstract = {Maximum likelihood (ML) estimation of simultaneous autocorrelation models is well known. Under the presence of missing data, estimation is not straightforward, due to the implied dependence of all units. The EM algorithm is the standard approach to accomplish ML estimation in this case. An alternative approach is considered, the method of maximising the marginal likelihood. At first glance the method is computationally complex due to inversion of large matrices that are of the same size as the complete data, but these can be avoided, leading to an algorithm that is usually much faster than the EM algorithm and without typical EM convergence issues. Another approximate method is also proposed that serves as an alternative, for example when the contiguity matrix is dense. The methods are illustrated using a well known data set on house prices with 25,357 units.},
   author = {Thomas Suesse},
   doi = {10.1016/j.csda.2017.11.004},
   issn = {01679473},
   journal = {Computational Statistics and Data Analysis},
   keywords = {EM algorithm,Marginal likelihood,Maximum likelihood,Missing data,SAR model},
   month = {4},
   pages = {98-110},
   publisher = {Elsevier B.V.},
   title = {Marginal maximum likelihood estimation of SAR models with missing data},
   volume = {120},
   year = {2018},
}
@inbook{Mcnally2007,
   author = {Michael G Mcnally},
   edition = {2},
   publisher = {Pergamon},
   title = {Handbook of Transport Modeling},
   url = {http://www.its.uci.edu},
   year = {2007},
}
@book{Rodrigue2006,
   author = {Jean-Paul Rodrigue and Claude Comtois and Brian Slack},
   title = {The Geography of Transport Systems},
   year = {2006},
}
@book{Cascetta2009,
   author = {Ennio Cascetta},
   doi = {10.1007/978-0-387-75857-2},
   edition = {2},
   editor = {Panos Pardalos and Ding-Zhu Du},
   isbn = {978-0-387-75856-5},
   month = {8},
   publisher = {Springer},
   title = {TRANSPORTATION SYSTEMS ANALYSIS},
   volume = {29},
   year = {2009},
}
@article{Karner2020,
   abstract = {Transportation policies, plans, and projects all flow through state institutions because of the substantial cost of infrastructure and the need to assess transportation system performance, including equity implications. But environmental justice scholarship interrogates the state’s role in perpetuating injustice. Most research and planning practice related to transportation equity has relied upon state-sponsored analytical methods. Transportation planners and scholars can benefit from critical assessments of these approaches. We propose a shift in focus from transportation equity to a broader consideration of transportation justice that is more closely aligned with models of social change promulgated in the environmental justice literature and by related movements.},
   author = {Alex Karner and Jonathan London and Dana Rowangould and Kevin Manaugh},
   doi = {10.1177/0885412220927691},
   issn = {15526593},
   issue = {4},
   journal = {Journal of Planning Literature},
   keywords = {community participation,environmental justice,social movements,state,transportation justice,transportation planning},
   month = {11},
   pages = {440-459},
   publisher = {SAGE Publications Inc.},
   title = {From Transportation Equity to Transportation Justice: Within, Through, and Beyond the State},
   volume = {35},
   year = {2020},
}
@article{Lee2018,
   abstract = {Spatial data relating to non-overlapping areal units are prevalent in fields such as economics, environmental science, epidemiology and social science, and a large suite of modeling tools have been developed for analysing these data. Many utilize conditional autoregressive (CAR) priors to capture the spatial autocorrelation inherent in these data, and software packages such as CARBayes and R-INLA have been developed to make these models easily accessible to others. Such spatial data are typically available for multiple time periods, and the development of methodology for capturing temporally changing spatial dynamics is the focus of much current research. A sizeable proportion of this literature has focused on extending CAR priors to the spatio-temporal domain, and this article presents the R package CARBayesST, which is the first dedicated software package for spatio-temporal areal unit modeling with conditional autoregressive priors. The software package allows to fit a range of models focused on different aspects of spacetime modeling, including estimation of overall space and time trends, and the identification of clusters of areal units that exhibit elevated values. This paper outlines the class of models that the software package implement, before applying them to simulated and two real examples from the fields of epidemiology and housing market analysis.},
   author = {Duncan Lee and Alastair Rushworth and Gary Napier},
   doi = {10.18637/jss.v084.i09},
   issn = {15487660},
   journal = {Journal of Statistical Software},
   keywords = {Bayesian inference,Conditional autoregressive priors,R package,Spatio-temporal areal unit modeling},
   publisher = {American Statistical Association},
   title = {Spatio-temporal areal unit modeling in R with conditional autoregressive priors using the CARBayesST package},
   volume = {84},
   year = {2018},
}
@inbook{Yeh2021,
   abstract = {In recent decades, cellular automata (CA) have become popular for evaluating and forecasting urban transformation over time and space, especially in rapidly developing countries. These models enhance the understanding of urban dynamics and the complex interplay between land-use changes and urban sustainability. CA help governments, planners, and stakeholders to predict and evaluate the potential outcomes of future policy alternatives before making decisions. Thus, CA are frequently used to create what-if scenarios for policy implementation. This chapter includes an overview of the basic and state-of-the-art concepts and methods in urban CA modeling, as well as the latest studies, applications, and current problems. First, we conduct a systematic review of urban CA modeling to provide critical comments on previous and recent studies. The basic techniques, including the components of a basic CA model, modifications for urban modeling, and collection of data sources, are then provided, along with a classification of different types of urban CA. Finally, the applications of CA in urban studies and planning practices are presented, as well as discussions of further research. We also point out the major problems in recent studies and applications for further research.},
   author = {Anthony G.O. Yeh and Xia Li and Chang Xia},
   doi = {10.1007/978-981-15-8983-6_45},
   issn = {23657588},
   journal = {Urban Book Series},
   pages = {865-883},
   publisher = {Springer Science and Business Media Deutschland GmbH},
   title = {Cellular Automata Modeling for Urban and Regional Planning},
   year = {2021},
}
@article{zandi2019,
   abstract = {The present descriptive-analytical study employs a survey research method, documentary technique, and applied-developmental research design to zone the 18 neighborhoods of Sabzevar City in terms of urban poverty indicators. Data collection was done through a questionnaire distributed among a sample with the size of 384 participants selected from for citizens of 18 neighborhoods of Sabzevar City. A total of 17 urban poverty indicators were surveyed in the form of three sociocultural, economic, and access to urban services indicators. For data analysis, the analytic network process (ANP), Grey Relational Analysis (GRA), and spatial statistics tests were used. The results of the integration of the three economic, sociocultural, and access to urban services indicators depict that the highest urban poverty is in neighborhoods 17 and 18, 6, 14, 15, 13, 12, 11, and 9 respectively. All these neighborhoods are among the marginal neighborhoods of the city. The lowest urban poverty levels are in neighborhoods 1, 2, 3, 4, 5 and partly in neighborhoods 13, 14 and 16, which are part of the city's central neighborhoods, mostly including government employees, the salaried, and those with high-paying jobs. Comparing different types of urban textures via the Integrated Zoning Map of Poverty in Sabzevar City shows that urban poverty zones correspond to the areas of unofficial settlements and extension villages, and the economic poverty in the southern regions of the city is higher than other urban areas. According to the principles of Grey Relational Analysis (GRA), neighborhoods 1 and 2, which includes Southern Kashifi St., Northern Asrar St., and Imam Khomeini Blvd., is considered to be at a higher level than other areas in terms of poor urban poverty. The results of spatial statistics tests (spatial autocorrelation test and G-test) indicate the correlation and clustering of the data model or urban poverty indicators of the study area.},
   author = {Rahman zandi and Mehdi Zanganeh and Ebrahim Akbari},
   doi = {10.1016/j.jum.2019.09.002},
   issn = {25890360},
   issue = {3},
   journal = {Journal of Urban Management},
   keywords = {ANP model,Grey relational analysis (GRA),Sabzevar city,Spatial statistics,Spatial structure analysis,Urban poverty},
   month = {12},
   pages = {342-354},
   publisher = {Elsevier B.V.},
   title = {Zoning and spatial analysis of poverty in urban areas (Case Study: Sabzevar City-Iran)},
   volume = {8},
   year = {2019},
}
@article{Chavent2018,
   abstract = {In this paper, we propose a Ward-like hierarchical clustering algorithm including spatial/geographical constraints. Two dissimilarity matrices D 0 and D 1 are inputted, along with a mixing parameter α ∈ [0, 1]. The dissimilarities can be non-Euclidean and the weights of the observations can be non-uniform. The first matrix gives the dissimilarities in the "feature space" and the second matrix gives the dissim-ilarities in the "constraint space". The criterion minimized at each stage is a convex combination of the homogeneity criterion calculated with D 0 and the homogeneity criterion calculated with D 1. The idea is then to determine a value of α which increases the spatial contiguity without deteriorating too much the quality of the solution based on the variables of interest i.e. those of the feature space. This procedure is illustrated on a real dataset using the R package ClustGeo.},
   author = {Marie Chavent and Vanessa Kuentz-Simonet and · Amaury Labenne and · Jérôme Saracco and Amaury Labenne and Jérôme Saracco},
   doi = {10.1007/s00180-018-0791-1},
   journal = {Computational Statistics},
   keywords = {Geographical distances,Non-Euclidean dissimilarities,Pseudo-inertia,Soft contiguity constraints,Ward-like hierarchical clustering},
   pages = {1799-1822},
   title = {ClustGeo: an R package for hierarchical clustering with spatial constraints},
   volume = {33},
   url = {https://doi.org/10.1007/s00180-018-0791-1},
   year = {2018},
}
@article{Bivand2021,
   abstract = {The software for spatial econometrics available in the R system for statistical computing is reviewed. The methods are illustrated in a historical perspective, highlighting the main lines of development and employing historically relevant datasets in the examples. Estimators and tests for spatial cross-sectional and panel models based either on maximum likelihood or on generalized moments methods are presented. The paper is concluded reviewing some current active lines of research in spatial econometric software methods.},
   author = {Roger Bivand and Giovanni Millo and Gianfranco Piras},
   doi = {10.3390/math9111276},
   keywords = {R,review,software,spatial econometrics},
   title = {mathematics A Review of Software for Spatial Econometrics in R},
   url = {https://doi.org/10.3390/math9111276},
   year = {2021},
}
@article{Chandra2021,
   abstract = {This paper contributes to the existing research on freight transportation, spatial and land use planning by investigating an improved spatial aggregation technique to delineate desirable freight traffic analysis zones. Zoning is a process of spatially aggregating several predefined basic spatial units (BSUs) into multiple zones. It plays a vital role in the transportation planning and decision-making process and is well-documented as the modifiable areal unit problem (MAUP). MAUP involves aggregating BSUs to obtain optimal zones satisfying specific criteria and constraints. This paper proposes an improved spatial aggregation methodology to develop a freight traffic analysis zone system by applying the multiobjective optimization concept using a genetic algorithm. The decision variables, namely, (i) Freight trip density; (ii) Number of establishments; (iii) Employment density; and (iv) Compactness, are chosen to represent the elements of freight, passenger traffic, and land use. The problem is formulated as a multiobjective network partitioning problem. The four objectives aim to create zones with better homogeneity and compactness. It is solved using a genetic algorithm with a weighted distance metric approach to prioritize the four objectives. Results show that zones resulting from the improved methodology are superior to the existing zones in terms of homogeneity of decision variables and compactness. The findings are expected to help the decision-making process of urban, transportation, and land-use planners in selecting appropriate freight traffic zone delineation strategies for a given region.},
   author = {Aitichya Chandra and M. N. Sharath and Agnivesh Pani and Prasanta K. Sahu},
   doi = {10.1016/j.jtrangeo.2021.103037},
   issn = {09666923},
   journal = {Journal of Transport Geography},
   keywords = {Freight traffic analysis zones,Freight transportation,Genetic algorithm,Land use,Multiobjective optimization,Spatial aggregation,Zoning scale},
   month = {4},
   publisher = {Elsevier Ltd},
   title = {A multi-objective genetic algorithm approach to design optimal zoning systems for freight transportation planning},
   volume = {92},
   year = {2021},
}
@book{Ortúzar1996,
   abstract = {Already the market leader in the field, Modelling Transport has become still more indispensible following a thorough and detailed update. Enhancements include two entirely new chapters on modelling for private sector projects and on activity-based modelling; a new section on dynamic assignment and micro-simulation; and sizeable updates to sections on disaggregate modelling and stated preference design and analysis. It also tackles topical issues such as valuation of externalities and the role of GPS in travel time surveys. Providing unrivalled depth and breadth of coverage, each topic is approached as a modelling exercise with discussion of the roles of theory, data, model specification, estimation, validation and application. The authors present the state of the art and its practical application in a pedagogic manner, easily understandable to both students and practitioners. Follows on from the highly successful third edition universally acknowledged as the leading text on transport modelling techniques and applications. Includes two new chapters on modelling for private sector projects and activity based modeling, and numerous updates to existing chapters. Incorporates treatment of recent issues and concerns like risk analysis and the dynamic interaction between land use and transport. Provides comprehensive and rigorous information and guidance, enabling readers to make practical use of every available technique. Relates the topics to new external factors and technologies such as global warming, valuation of externalities and global positioning systems (GPS). © 2011 John Wiley & Sons, Ltd.},
   author = {Juan de Dios Ortúzar and Luis G. Willumsen},
   edition = {2},
   isbn = {0 471 94193 X},
   journal = {Modelling Transport},
   month = {7},
   publisher = {John Wiley and Sons},
   title = {Modelling Transport},
   year = {1996},
}
@article{Ortúzar2003,
   abstract = {Disaggregate models, based on the study of individual's behavior making their consumption choices, are considered today the rigth tool in the analysis and predition of demand. This discipline has experienced an increasing development in the last decades, both in a methodological and emprirical level. In this article, an actualized overview of the problem of demand modeling from a disaggregate perspective is presented, emphasizing the case of the transport, in wich the mayor part of the applications has been developed. Microeconomical basis, the most important aspects related to modeling and the sources of information of this modeles are analyzed. In relation with this sources, a special mention about the modeling with declared preferences and mixed data is made. Resumen Los modelos desagregados, basados en el estudio del comportamiento de los individuos a la hora de tomar sus decisiones de consumo, constituyen hoy por hoy la herramienta adecuada en el análisis y predicción de la demanda. Esta disciplina ha experimentado un creciente desarrollo en las últimas décadas, tanto a nivel metodológico como empírico. En este artículo se presenta una panorámica general actualizada del problema de la modelización de la de-manda desde una perspectiva desagregada, haciendo especial hincapié en el caso del trans-porte, donde se han desarrollado la mayor parte de las aplicaciones. Se analizan los funda-mentos microeconómicos, los aspectos más relevantes relacionados con la modelización y las fuentes de información de las que se nutren estos modelos. En relación a estas últimas se hace una mención especial a la modelización con datos de preferencias declaradas y datos mixtos. Esta sección está destinada a recoger artículos que, pese a no estar referidos explícitamente a temas urbanos y/o territoriales, pueden ser de interés para los lectores de EURE. El artículo que se publica en esta oportunidad fue invitado por las autoridades que se desempeñaron hasta el número 85 de la Revista, invitación que la actual Dirección ha entendido pertinente mantener. artículos especiales invitados},
   author = {Juan De Dios Ortúzar and Concepción Román},
   journal = {Revista eure},
   keywords = {demand,disaggregate models,methodology Palabras clave: demanda,metodología,modelos desagregados,transport,transporte},
   pages = {149-171},
   title = {El problema de modelación de demanda desde una perspectiva desagregada: el caso del transporte ****},
   volume = {88},
   year = {2003},
}
@report{Daly1990,
   abstract = {An important issue in the design of a transportation planning study is the level of aggregation that is selected for the measurement of data. In general, a higher level of disaggregation, giving a greater level of accuracy, will improve the quality of forecasting models but increase the cost of data collection and of other aspects of the modelling exercise. Clearly, some data items give a better return on the investment of effort in increasing their accuracy: the problem is to optimise the return on the investment of a fixed budget over all the data to be collected. The resulting pattern of investment may well be different for different sub-models in the transportation planning system. This paper addresses the problem of determining appropriate levels of data aggregation for two key travel demand forecasting models: those predicting destination choice (or trip distribution) and mode choice. These choice processes may be treated separately or, as is now becoming more common, in a joint modelling procedure. They have been chosen for study in this paper because of their intrinsic importance and because of the availability of results from a number of studies that serve to illustrate key points. The objective of the paper is to provide indications for the practitioner for appropriate aggregation levels to be used in empirical studies. The recommendations are supported by theoretical discussions and practical findings.},
   author = {A J Daly and J De and D Ortúzar},
   title = {Draft 12 August 1990 FORECASTING AND DATA AGGREGATION: THEORY AND PRACTICE},
   year = {1990},
}
